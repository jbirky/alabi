<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html"><link rel="prev" title="alabi" href="modules.html">
        <link rel="canonical" href="https://alabi.jessicabirky.com/alabi.html">

    <!-- Generated with Sphinx 9.0.4 and Furo 2025.12.19 -->
        <title>alabi package - alabi</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=0cf789f7" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --font-stack: Roboto Light, sans-serif;
  --font-stack--monospace: Courier, monospace;
  --color-background-secondary: #eff1f6;
  --color-inline-code-background: #eff1f6;
  --color-sidebar-item-background--hover: white;
  --color-brand-primary: #004080;
  --color-brand-content: #0059b3;
  --font-size--small: 0.875rem;
  --font-size--normal: 1rem;
  --font-size--large: 1.125rem;
  --font-size-h1: 2.2rem;
  --font-size-h2: 1.8rem;
  --font-size-h3: 1.5rem;
  --font-size-h4: 1.3rem;
  --font-size-h5: 1.1rem;
  --font-size-h6: 1rem;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">alabi</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <span class="sidebar-brand-text">alabi</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Intro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html#quickstart-example">Quickstart Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_reload.html">Saving and Reloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp_tutorial.html">GP Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc_tutorial.html">MCMC sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_bayesian_optimization.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_hp_settings.html">Automated Hyperparameter Selection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="plot_demo_1d.html">Visualize Active Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_demo_2d.html">Test 2D Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_line_fit.html">Fit a line to data</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_kl_divergence.html">KL Divergence: Gaussian</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_gaussian_nd.html">Test computational scaling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Applications</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="trappist_stellar_evolution.html">Stellar Evolution</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">alabi</a><input aria-label="Toggle navigation of alabi" checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">alabi package</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/jbirky/alabi">GitHub Repository</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/jbirky/alabi/LICENSE">License</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/jbirky/alabi/issues">Issues</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/alabi.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="alabi-package">
<h1>alabi package<a class="headerlink" href="#alabi-package" title="Link to this heading">¶</a></h1>
<section id="module-alabi.benchmarks">
<span id="alabi-benchmarks-module"></span><h2>alabi.benchmarks module<a class="headerlink" href="#module-alabi.benchmarks" title="Link to this heading">¶</a></h2>
<section id="benchmarks-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">benchmarks.py</span></code><a class="headerlink" href="#benchmarks-py" title="Link to this heading">¶</a></h3>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.benchmarks.random_gaussian_covariance">
<span class="sig-prename descclassname"><span class="pre">alabi.benchmarks.</span></span><span class="sig-name descname"><span class="pre">random_gaussian_covariance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_dims</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/benchmarks.html#random_gaussian_covariance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.benchmarks.random_gaussian_covariance" title="Link to this definition">¶</a></dt>
<dd><p>Generate a random positive definite covariance matrix.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.benchmarks.multimodal_gaussian_nd">
<span class="sig-prename descclassname"><span class="pre">alabi.benchmarks.</span></span><span class="sig-name descname"><span class="pre">multimodal_gaussian_nd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">means</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/benchmarks.html#multimodal_gaussian_nd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.benchmarks.multimodal_gaussian_nd" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-alabi.cache_utils">
<span id="alabi-cache-utils-module"></span><h2>alabi.cache_utils module<a class="headerlink" href="#module-alabi.cache_utils" title="Link to this heading">¶</a></h2>
<section id="cache-utils-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">cache_utils.py</span></code><a class="headerlink" href="#cache-utils-py" title="Link to this heading">¶</a></h3>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.cache_utils.load_pickle">
<span class="sig-prename descclassname"><span class="pre">alabi.cache_utils.</span></span><span class="sig-name descname"><span class="pre">load_pickle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'surrogate_model.pkl'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/cache_utils.html#load_pickle"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.cache_utils.load_pickle" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.cache_utils.load_model_cache">
<span class="sig-prename descclassname"><span class="pre">alabi.cache_utils.</span></span><span class="sig-name descname"><span class="pre">load_model_cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/cache_utils.html#load_model_cache"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.cache_utils.load_model_cache" title="Link to this definition">¶</a></dt>
<dd><p>MPI-safe model loading that prevents file corruption.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>savedir</strong> – Directory containing the model cache</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loaded surrogate model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.cache_utils.write_report_gp">
<span class="sig-prename descclassname"><span class="pre">alabi.cache_utils.</span></span><span class="sig-name descname"><span class="pre">write_report_gp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/cache_utils.html#write_report_gp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.cache_utils.write_report_gp" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.cache_utils.write_report_emcee">
<span class="sig-prename descclassname"><span class="pre">alabi.cache_utils.</span></span><span class="sig-name descname"><span class="pre">write_report_emcee</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/cache_utils.html#write_report_emcee"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.cache_utils.write_report_emcee" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.cache_utils.write_report_dynesty">
<span class="sig-prename descclassname"><span class="pre">alabi.cache_utils.</span></span><span class="sig-name descname"><span class="pre">write_report_dynesty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/cache_utils.html#write_report_dynesty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.cache_utils.write_report_dynesty" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-alabi.core">
<span id="alabi-core-module"></span><h2>alabi.core module<a class="headerlink" href="#module-alabi.core" title="Link to this heading">¶</a></h2>
<section id="core-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">core.py</span></code><a class="headerlink" href="#core-py" title="Link to this heading">¶</a></h3>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">alabi.core.</span></span><span class="sig-name descname"><span class="pre">SurrogateModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lnlike_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savedir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'results/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'surrogate_model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ncore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'forkserver'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_warnings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Gaussian Process surrogate model for Bayesian inference and optimization.</p>
<p>A SurrogateModel uses a Gaussian Process to create a fast approximation of expensive
likelihood functions, enabling efficient Bayesian inference, parameter estimation,
and active learning. The model supports various active learning algorithms and 
scalers for handling different types of likelihood functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lnlike_fn</strong> – (<em>callable, required</em>)
Log-likelihood function that takes parameter array theta and returns scalar 
log-likelihood value. For Bayesian inference, this is your model’s log-likelihood.
Signature: lnlike_fn(theta) -&gt; float</p></li>
<li><p><strong>bounds</strong> – (<em>array-like, required</em>)
Prior bounds for each parameter. List/array of (min, max) tuples for each dimension.
Example: bounds = [(0, 1), (2, 3), (-1, 1)]</p></li>
<li><p><strong>param_names</strong> – (<em>array-like, optional</em>)
Names/labels for each parameter. If None, defaults to θ₀, θ₁, etc.
Length must match number of dimensions in bounds.</p></li>
<li><p><strong>cache</strong> – (<em>bool, optional, default=True</em>)
Whether to cache the trained model to disk for reuse</p></li>
<li><p><strong>savedir</strong> – (<em>str, optional, default=”results/”</em>)
Directory for saving results, plots, and cached models</p></li>
<li><p><strong>model_name</strong> – (<em>str, optional, default=”surrogate_model”</em>)
Name prefix for cached model files</p></li>
<li><p><strong>verbose</strong> – (<em>bool, optional, default=True</em>)
Print progress information during training and inference</p></li>
<li><p><strong>ncore</strong> – (<em>int, optional, default=cpu_count()</em>)
Number of CPU cores to use for parallel computation</p></li>
<li><p><strong>ignore_warnings</strong> – (<em>bool, optional, default=True</em>)
Suppress sklearn and other package warnings</p></li>
<li><p><strong>random_state</strong> – (<em>int, optional, default=None</em>)
Random seed for reproducible results</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.gp">
<span class="sig-name descname"><span class="pre">gp</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">george.GP</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.gp" title="Link to this definition">¶</a></dt>
<dd><p>Trained Gaussian Process model</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.bounds">
<span class="sig-name descname"><span class="pre">bounds</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.bounds" title="Link to this definition">¶</a></dt>
<dd><p>Original parameter bounds (unscaled)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel._bounds">
<span class="sig-name descname"><span class="pre">_bounds</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel._bounds" title="Link to this definition">¶</a></dt>
<dd><p>Scaled parameter bounds used for GP training</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel._theta">
<span class="sig-name descname"><span class="pre">_theta</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel._theta" title="Link to this definition">¶</a></dt>
<dd><p>Training parameter samples (scaled)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel._y">
<span class="sig-name descname"><span class="pre">_y</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel._y" title="Link to this definition">¶</a></dt>
<dd><p>Training likelihood values (scaled)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.ntrain">
<span class="sig-name descname"><span class="pre">ntrain</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.ntrain" title="Link to this definition">¶</a></dt>
<dd><p>Number of initial training samples</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.ndim">
<span class="sig-name descname"><span class="pre">ndim</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.ndim" title="Link to this definition">¶</a></dt>
<dd><p>Number of parameters/dimensions</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.emcee_samples">
<span class="sig-name descname"><span class="pre">emcee_samples</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.emcee_samples" title="Link to this definition">¶</a></dt>
<dd><p>MCMC samples from emcee (if run_emcee called)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.dynesty_samples">
<span class="sig-name descname"><span class="pre">dynesty_samples</span></span><span class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></span><a class="headerlink" href="#alabi.core.SurrogateModel.dynesty_samples" title="Link to this definition">¶</a></dt>
<dd><p>Nested sampling results from dynesty (if run_dynesty called)</p>
</dd></dl>

<p><strong>Examples</strong></p>
<p>Basic usage for Bayesian inference:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">log_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="c1"># Your model likelihood function</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">theta</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>  <span class="c1"># 2D parameter space</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">SurrogateModel</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
<span class="n">sm</span><span class="o">.</span><span class="n">init_samples</span><span class="p">(</span><span class="n">ntrain</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># Initial training data</span>
<span class="n">sm</span><span class="o">.</span><span class="n">init_gp</span><span class="p">()</span>  <span class="c1"># Initialize Gaussian Process</span>
<span class="n">sm</span><span class="o">.</span><span class="n">active_train</span><span class="p">(</span><span class="n">niter</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># Active learning</span>
<span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">()</span>  <span class="c1"># Bayesian inference</span>
</pre></div>
</div>
<p>For optimization problems:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">active_train</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;jones&quot;</span><span class="p">)</span>  <span class="c1"># Use Jones algorithm for optimization</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#alabi.core.SurrogateModel.init_samples" title="alabi.core.SurrogateModel.init_samples"><code class="xref py py-meth docutils literal notranslate"><span class="pre">init_samples()</span></code></a> : Initialize training data
<a class="reference internal" href="#alabi.core.SurrogateModel.init_gp" title="alabi.core.SurrogateModel.init_gp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">init_gp()</span></code></a> : Initialize Gaussian Process
<a class="reference internal" href="#alabi.core.SurrogateModel.active_train" title="alabi.core.SurrogateModel.active_train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">active_train()</span></code></a> : Perform active learning
<a class="reference internal" href="#alabi.core.SurrogateModel.run_dynesty" title="alabi.core.SurrogateModel.run_dynesty"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run_dynesty()</span></code></a> : Run nested sampling with dynesty
<a class="reference internal" href="#alabi.core.SurrogateModel.run_emcee" title="alabi.core.SurrogateModel.run_emcee"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run_emcee()</span></code></a> : Run MCMC sampling with emcee
<a class="reference internal" href="#alabi.core.SurrogateModel.run_ultranest" title="alabi.core.SurrogateModel.run_ultranest"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run_ultranest()</span></code></a> : Run nested sampling with UltraNest
<a class="reference internal" href="#alabi.core.SurrogateModel.run_pymultinest" title="alabi.core.SurrogateModel.run_pymultinest"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run_pymultinest()</span></code></a> : Run nested sampling with PyMultiNest</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lnlike_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savedir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'results/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'surrogate_model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ncore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'forkserver'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_warnings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.save" title="Link to this definition">¶</a></dt>
<dd><p>Pickle <code class="docutils literal notranslate"><span class="pre">SurrogateModel</span></code> object and write summary to a text file.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.theta">
<span class="sig-name descname"><span class="pre">theta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.theta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.theta" title="Link to this definition">¶</a></dt>
<dd><p>Return unscaled training theta values</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.y">
<span class="sig-name descname"><span class="pre">y</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.y"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.y" title="Link to this definition">¶</a></dt>
<dd><p>Return unscaled training y values</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.refit_scalers">
<span class="sig-name descname"><span class="pre">refit_scalers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta_scaler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_scaler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.refit_scalers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.refit_scalers" title="Link to this definition">¶</a></dt>
<dd><p>Refit the theta and y scalers using current training data.
Useful if training data has changed significantly.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.init_train">
<span class="sig-name descname"><span class="pre">init_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'initial_training_sample.npz'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.init_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.init_train" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nsample</strong> – (<em>int, optional</em>) 
Number of samples. Defaults to <code class="docutils literal notranslate"><span class="pre">nsample</span> <span class="pre">=</span> <span class="pre">50</span> <span class="pre">*</span> <span class="pre">self.ndim</span></code></p></li>
<li><p><strong>sampler</strong> – (<em>str, optional</em>) 
Sampling method. Defaults to <code class="docutils literal notranslate"><span class="pre">'sobol'</span></code>. 
See <code class="docutils literal notranslate"><span class="pre">utility.prior_sampler</span></code> for more details.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.load_train">
<span class="sig-name descname"><span class="pre">load_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cache_file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.load_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.load_train" title="Link to this definition">¶</a></dt>
<dd><p>Reload training samples from cache file and apply scalers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>cache_file</strong> – (<em>str, required</em>) 
Name of cache file relative to savedir. Must be a .npz file containing ‘theta’ and ‘y’ arrays.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(<em>tuple</em>) 
Scaled training samples (_theta, _y) after loading from cache.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.init_samples">
<span class="sig-name descname"><span class="pre">init_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ntrain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntest</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.init_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.init_samples" title="Link to this definition">¶</a></dt>
<dd><p>Initialize training and test samples for the surrogate model.</p>
<p>Creates initial dataset by either loading cached samples or computing new ones
by evaluating the likelihood function at randomly sampled parameter values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ntrain</strong> – (<em>int, optional, default=100</em>)
Number of training samples to generate. Used only if not loading cached samples.</p></li>
<li><p><strong>ntest</strong> – (<em>int, optional, default=0</em>)
Number of test samples to generate. Currently unused.</p></li>
<li><p><strong>sampler</strong> – <p>(<em>str, optional, default=”uniform”</em>)
Sampling method for generating parameter values. Options:</p>
<ul>
<li><p>”uniform”: Uniform sampling within bounds (default)</p></li>
<li><p>”sobol”: Low-discrepancy Sobol sequence sampling</p></li>
<li><p>”lhs”: Latin hypercube sampling</p></li>
</ul>
</p></li>
<li><p><strong>train_file</strong> – (<em>str, optional, default=”initial_training_sample.npz”</em>)
Filename for cached training samples relative to savedir.
Format: .npz file containing ‘theta’ and ‘y’ arrays.</p></li>
<li><p><strong>test_file</strong> – (<em>str, optional, default=”initial_test_sample.npz”</em>)
Filename for cached test samples relative to savedir. Currently unused.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.set_hyperparam_prior_bounds">
<span class="sig-name descname"><span class="pre">set_hyperparam_prior_bounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.set_hyperparam_prior_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.set_hyperparam_prior_bounds" title="Link to this definition">¶</a></dt>
<dd><p>Configure prior bounds for GP hyperparameters based on current training data.</p>
<dl class="simple">
<dt>By default ranges for parameters:</dt><dd><ul class="simple">
<li><p>mean: [mean(y) - std(y), mean(y) + std(y)]</p></li>
<li><p>amplitude: [0.1, 10]</p></li>
<li><p>white noise: [white_noise - 3, white_noise + 3]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.expand_hyperparameter_vector">
<span class="sig-name descname"><span class="pre">expand_hyperparameter_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimized_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.expand_hyperparameter_vector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.expand_hyperparameter_vector" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.set_hyperparameter_vector">
<span class="sig-name descname"><span class="pre">set_hyperparameter_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tmp_gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimized_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.set_hyperparameter_vector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.set_hyperparameter_vector" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.get_hyperparameter_dict">
<span class="sig-name descname"><span class="pre">get_hyperparameter_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.get_hyperparameter_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.get_hyperparameter_dict" title="Link to this definition">¶</a></dt>
<dd><p>Get current GP hyperparameters as a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>(<em>dict</em>) 
Dictionary of current GP hyperparameters with names as keys and values as values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.get_hyperparameter_vector">
<span class="sig-name descname"><span class="pre">get_hyperparameter_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.get_hyperparameter_vector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.get_hyperparameter_vector" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.init_gp">
<span class="sig-name descname"><span class="pre">init_gp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ExpSquaredKernel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_amp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_white_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">white_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_scale_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[-2,</span> <span class="pre">2]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_amp_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[-1,</span> <span class="pre">1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">uniform_scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta_scaler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">no_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_scaler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">no_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_opt_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l-bfgs-b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_nopt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'adaptive':</span> <span class="pre">True,</span> <span class="pre">'fatol':</span> <span class="pre">0.001,</span> <span class="pre">'maxiter':</span> <span class="pre">100,</span> <span class="pre">'xatol':</span> <span class="pre">0.0001}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperopt_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_stage2_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_stage2_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_stage3_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_stage3_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_weighted_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_proc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.init_gp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.init_gp" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the Gaussian Process surrogate model with specified kernel and hyperparameters.</p>
<p>This function sets up a Gaussian Process (GP) using the george library with the specified 
kernel type and configuration. The GP is initialized with random scale lengths and then
fitted to the current training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – <p>(<em>str or george kernel object, optional</em>) 
Kernel type for the Gaussian Process. Can be either a string specifying one of the 
built-in kernels or a george kernel object. Default is “ExpSquaredKernel”.</p>
<dl class="simple">
<dt>Built-in options:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'ExpSquaredKernel'</span></code>: Squared exponential (RBF) kernel, smooth functions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Matern32Kernel'</span></code>: Matérn kernel with ν=3/2, moderately smooth functions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'Matern52Kernel'</span></code>: Matérn kernel with ν=5/2, smooth functions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'RationalQuadraticKernel'</span></code>: Rational quadratic kernel, scale mixture of RBF kernels</p></li>
</ul>
</dd>
</dl>
<p>See <a class="reference external" href="https://george.readthedocs.io/en/latest/user/kernels/">https://george.readthedocs.io/en/latest/user/kernels/</a> for more details.</p>
</p></li>
<li><p><strong>fit_amp</strong> – (<em>bool, optional</em>) 
Whether to optimize the amplitude (overall scale) hyperparameter of the kernel.
If True, the GP will learn the optimal amplitude from data. Default is True.</p></li>
<li><p><strong>fit_mean</strong> – (<em>bool, optional</em>) 
Whether to optimize the mean function hyperparameter. If True, the GP will learn
a constant mean offset. If False, assumes zero mean. Default is True.</p></li>
<li><p><strong>fit_white_noise</strong> – (<em>bool, optional</em>) 
Whether to optimize the white noise (nugget) hyperparameter. If True, the GP will
learn the optimal noise level. If False, uses the fixed value from white_noise.
Default is True.</p></li>
<li><p><strong>white_noise</strong> – (<em>float, optional</em>) 
Log-scale white noise parameter. If fit_white_noise=False, this fixed value is used.
If fit_white_noise=True, this serves as the initial guess. Typical values are 
between -15 (very low noise) and -5 (high noise). Default is -12.</p></li>
<li><p><strong>gp_scale_rng</strong> – (<em>list of two floats, optional</em>) 
Log-scale bounds for the characteristic length scale parameters of the kernel.
Format: [log_min_scale, log_max_scale]. These bounds apply to all input dimensions.
Default is [-2, 2], corresponding to scales between ~0.14 and ~7.4 in original units.</p></li>
<li><p><strong>uniform_scales</strong> – (<em>bool, optional</em>) 
If True, the same scale length will be used for all input dimensions. If False, each dimension
will have its own independent scale length. Default is False.</p></li>
<li><p><strong>overwrite</strong> – (<em>bool, optional</em>) 
If True, allows reinitializing the GP even if one already exists. If False and a GP
already exists, raises an AssertionError. Default is False.</p></li>
<li><p><strong>theta_scaler</strong> – (<em>sklearn transformer, optional, default=no_scaler</em>)
Scaler for input parameters. Applied to theta values before GP training.
Common options: MinMaxScaler() (scale to [0,1]) or StandardScaler()</p></li>
<li><p><strong>y_scaler</strong> – (<em>sklearn transformer, optional, default=no_scaler</em>)
Scaler for output values (log-likelihoods). Options include:
- no_scaler: No scaling (default)
- minmax_scaler: Scale to [0,1] 
- nlog_scaler: Apply -log10(-y) transformation for negative log-likelihoods
- log_scaler: Apply log10(y) for positive values</p></li>
<li><p><strong>gp_opt_method</strong> – (<em>str, optional</em>) 
Optimization method for GP hyperparameter optimization. Passed to scipy.optimize.minimize.
Common options: ‘l-bfgs-b’, ‘newton-cg’, ‘bfgs’, ‘cg’. Default is ‘l-bfgs-b’.</p></li>
<li><p><strong>gp_nopt</strong> – (<em>int, optional</em>) 
Number of optimization restarts for GP hyperparameter optimization. Multiple restarts
help avoid local minima. Default is 3.</p></li>
<li><p><strong>optimizer_kwargs</strong> – (<em>dict, optional</em>) 
Additional keyword arguments passed to the scipy optimizer. Common options include
‘maxiter’ (maximum iterations) and convergence tolerances. 
Default is {“maxiter”: 50}.</p></li>
<li><p><strong>hyperopt_method</strong> – <p>(<em>str, optional, default=’ml’</em>)
Method for optimizing GP hyperparameters:</p>
<ul>
<li><p>’ml’: Maximum marginal likelihood (fast, may overfit)</p></li>
<li><p>’cv’: k-fold cross-validation (slower, prevents overfitting)</p></li>
</ul>
</p></li>
<li><p><strong>cv_folds</strong> – (<em>int, optional, default=5</em>)
Number of folds for cross-validation (only used if hyperopt_method=’cv’).</p></li>
<li><p><strong>cv_scoring</strong> – (<em>str, optional, default=’mse’</em>)
Scoring metric for cross-validation. Options: ‘mse’, ‘mae’, ‘r2’.</p></li>
<li><p><strong>cv_n_candidates</strong> – (<em>int, optional, default=20</em>)
Number of hyperparameter candidates to evaluate for CV.</p></li>
<li><p><strong>cv_stage2_candidates</strong> – (<em>int, optional, default=20</em>)
Number of candidates for stage 2 grid search. Only used when cv_two_stage=True.</p></li>
<li><p><strong>cv_stage2_width</strong> – (<em>float, optional, default=0.3</em>)
Width factor for stage 2 search around best parameters from stage 1.
Smaller values = tighter search. Only used when cv_two_stage=True.</p></li>
<li><p><strong>cv_stage3_candidates</strong> – (<em>int, optional, default=None</em>)
Number of candidates for stage 3 ultra-fine search. If None, uses 
max(cv_stage2_candidates // 2, 3). Only used when cv_three_stage=True.</p></li>
<li><p><strong>cv_stage3_width</strong> – (<em>float, optional, default=0.2</em>)
Width factor for stage 3 search around best parameters from stage 2.
Should be smaller than cv_stage2_width for finer refinement.
Only used when cv_three_stage=True.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If a GP already exists and overwrite=False.</p></li>
<li><p><strong>ValueError</strong> – If an invalid kernel name is provided.</p></li>
<li><p><strong>Exception</strong> – If GP initialization fails after multiple attempts with different scale lengths.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function must be called after init_samples() since it requires training data
to initialize the GP. The function will automatically retry initialization with
different random scale lengths if the initial attempt fails.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Basic initialization with default settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">init_gp</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Custom kernel with specific hyperparameter settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">init_gp</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;Matern52Kernel&quot;</span><span class="p">,</span> 
<span class="gp">... </span>           <span class="n">fit_white_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
<span class="gp">... </span>           <span class="n">white_noise</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">gp_scale_rng</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># High-precision optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">init_gp</span><span class="p">(</span><span class="n">gp_opt_method</span><span class="o">=</span><span class="s2">&quot;l-bfgs-b&quot;</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">gp_nopt</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;ftol&quot;</span><span class="p">:</span> <span class="mf">1e-9</span><span class="p">})</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.eval_gp_at_iteration">
<span class="sig-name descname"><span class="pre">eval_gp_at_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.eval_gp_at_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.eval_gp_at_iteration" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.surrogate_log_likelihood">
<span class="sig-name descname"><span class="pre">surrogate_log_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta_xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.surrogate_log_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.surrogate_log_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate predictive mean of the GP at point(s) <code class="docutils literal notranslate"><span class="pre">theta_xs</span></code></p>
<p>This method is vectorized to handle both single parameter vectors and
arrays of parameter vectors efficiently.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta_xs</strong> (<em>array-like</em>) – Point(s) to evaluate GP mean at. Can be:
- 1D array of shape (ndim,) for single point
- 2D array of shape (npoints, ndim) for multiple points</p></li>
<li><p><strong>iter</strong> (<em>int, optional</em>) – Iteration number of GP to use. If -1, uses most recent GP.</p></li>
<li><p><strong>return_var</strong> (<em>bool, optional</em>) – Whether to also return variance predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ypred</strong> (<em>array</em>) – GP mean(s) evaluated at <code class="docutils literal notranslate"><span class="pre">theta_xs</span></code>. Shape matches input.</p></li>
<li><p><strong>varpred</strong> (<em>array, optional</em>) – GP variance(s) if return_var=True.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>array or tuple of arrays</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.surrogate_likelihood">
<span class="sig-name descname"><span class="pre">surrogate_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta_xs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.surrogate_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.surrogate_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate predictive probability (not log-probability) of the GP at point(s) theta_xs</p>
<p>This method is vectorized to handle both single parameter vectors and
arrays of parameter vectors efficiently.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>theta_xs</strong> (<em>array-like</em>) – Point(s) to evaluate GP probability at. Can be:
- 1D array of shape (ndim,) for single point
- 2D array of shape (npoints, ndim) for multiple points</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GP probability/probabilities evaluated at <code class="docutils literal notranslate"><span class="pre">theta_xs</span></code>. Shape matches input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>float or array</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.create_cached_surrogate_likelihood">
<span class="sig-name descname"><span class="pre">create_cached_surrogate_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.create_cached_surrogate_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.create_cached_surrogate_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Create a cached surrogate likelihood function that computes the GP once
and can be evaluated multiple times without recomputing the GP.</p>
<p>This is useful when you need to evaluate the surrogate likelihood at many
different points with the same GP configuration, as it avoids the expensive
GP computation (gp.compute()) on each call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>iter</strong> (<em>int, optional</em>) – Iteration number of GP to use. If -1, uses most recent GP.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A cached likelihood function that can be called with theta_xs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>callable</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.find_next_point">
<span class="sig-name descname"><span class="pre">find_next_point</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nopt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.find_next_point"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.find_next_point" title="Link to this definition">¶</a></dt>
<dd><p>Find next set of <code class="docutils literal notranslate"><span class="pre">(theta,</span> <span class="pre">y)</span></code> training points by maximizing the
active learning utility function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nopt</strong> – (<em>int, optional</em>) 
Number of times to restart the objective function optimization. 
Defaults to 1. Increase to avoid converging to local minima.</p></li>
<li><p><strong>optimizer_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to scipy optimizer. Default is {}.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.active_train">
<span class="sig-name descname"><span class="pre">active_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">niter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bape'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_opt_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj_opt_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l-bfgs-b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nopt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_grad_opt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_opt_multiproc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_attempts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.active_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.active_train" title="Link to this definition">¶</a></dt>
<dd><p>Perform active learning to iteratively improve the surrogate model.</p>
<p>Uses acquisition functions to intelligently select new training points that
will most improve the Gaussian Process model. Different algorithms balance
exploration (uncertainty reduction) vs exploitation (finding optima).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>niter</strong> – (<em>int, optional, default=100</em>)
Number of active learning iterations. Each iteration adds one new training point.</p></li>
<li><p><strong>algorithm</strong> – (<em>str, optional, default=”bape”</em>)
Active learning algorithm. Options:
- “bape”: Bayesian Active Parameter Estimation (exploration-focused)
- “jones”: Jones algorithm (exploitation-focused, good for optimization)
- “agp”: Augmented Gaussian Process (balanced)
- “alternate”: Alternates between exploration and exploitation</p></li>
<li><p><strong>gp_opt_freq</strong> – (<em>int, optional, default=20</em>)
Frequency of GP hyperparameter re-optimization. GP hyperparameters are
re-optimized every gp_opt_freq iterations. Lower values = more optimization.</p></li>
<li><p><strong>save_progress</strong> – (<em>bool, optional, default=False</em>)
Whether to save training progress data for later analysis.</p></li>
<li><p><strong>obj_opt_method</strong> – (<em>str, optional, default=”nelder-mead”</em>)
Optimization method for acquisition function. Options:
- “l-bfgs-b”: L-BFGS-B (good with gradients)
- “nelder-mead”: Nelder-Mead simplex (gradient-free)</p></li>
<li><p><strong>nopt</strong> – (<em>int, optional, default=1</em>)
Number of optimization restarts for acquisition function. Higher values
help avoid local minima but increase computation time.</p></li>
<li><p><strong>use_grad_opt</strong> – (<em>bool, optional, default=True</em>)
Whether to use gradient information if available. Set False for
gradient-free optimization.</p></li>
<li><p><strong>optimizer_kwargs</strong> – (<em>dict, optional, default={}</em>)
Additional keyword arguments passed to the optimizer.</p></li>
<li><p><strong>show_progress</strong> – (<em>bool, optional, default=True</em>)
Whether to display progress bar during training.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Active learning algorithms have different purposes:</p>
<ul class="simple">
<li><p><strong>BAPE</strong>: Best for uncertainty quantification and space-filling</p></li>
<li><p><strong>Jones</strong>: Best for finding likelihood maxima/minima (optimization)</p></li>
<li><p><strong>Alternate</strong>: Good balance for both exploration and exploitation</p></li>
<li><p><strong>AGP</strong>: Another balanced approach</p></li>
</ul>
<p>The method automatically handles GP re-training and hyperparameter optimization
based on the specified frequency. Training data is accumulated in _theta and _y
attributes.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>Basic active learning with BAPE:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">active_train</span><span class="p">(</span><span class="n">niter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;bape&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Optimization-focused active learning:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">active_train</span><span class="p">(</span><span class="n">niter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;jones&quot;</span><span class="p">,</span> <span class="n">gp_opt_freq</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Balanced approach with frequent GP optimization:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">active_train</span><span class="p">(</span><span class="n">niter</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;alternate&quot;</span><span class="p">,</span> <span class="n">gp_opt_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.active_train_parallel">
<span class="sig-name descname"><span class="pre">active_train_parallel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">niter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nchains</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bape'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_opt_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj_opt_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nelder-mead'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nopt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_grad_opt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.active_train_parallel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.active_train_parallel" title="Link to this definition">¶</a></dt>
<dd><p>Run multiple active learning chains in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>niter</strong> – (<em>int, optional</em>) 
Number of iterations per chain. Default 100.</p></li>
<li><p><strong>nchains</strong> – (<em>int, optional</em>) 
Number of parallel chains to run. Default 4.</p></li>
<li><p><strong>algorithm</strong> – (<em>str, optional</em>) 
Active learning algorithm. Default “bape”.</p></li>
<li><p><strong>gp_opt_freq</strong> – (<em>int, optional</em>)
Frequency of GP hyperparameter optimization. Default 20.</p></li>
<li><p><strong>obj_opt_method</strong> – (<em>str, optional</em>)
Optimization method for acquisition function. Default “nelder-mead”.</p></li>
<li><p><strong>nopt</strong> – (<em>int, optional</em>)
Number of restarts for acquisition optimization. Default 1.</p></li>
<li><p><strong>use_grad_opt</strong> – (<em>bool, optional</em>)
Whether to use gradient-based optimization. Default True.</p></li>
<li><p><strong>optimizer_kwargs</strong> – (<em>dict, optional</em>)
Additional optimizer kwargs. Default {}.</p></li>
<li><p><strong>show_progress</strong> – (<em>bool, optional</em>) 
Whether to display progress bar during parallel chain execution. Default is True.</p></li>
</ul>
</dd>
</dl>
<section id="notes">
<h3>Notes<a class="headerlink" href="#notes" title="Link to this heading">¶</a></h3>
<p>This function uses multiprocessing.Pool instead of threading, which can provide
better performance for CPU-intensive tasks and avoids GIL limitations. However:</p>
<ul class="simple">
<li><p>All model data must be pickleable (which it should be for SurrogateModel)</p></li>
<li><p>Each process runs in separate memory space (higher memory usage)</p></li>
<li><p>Process startup overhead is higher than threading</p></li>
<li><p>Better isolation between chains (one chain failure won’t affect others)</p></li>
<li><p>Can achieve true parallelism on multi-core systems</p></li>
</ul>
<p>The function automatically respects the ncore limit and won’t create more processes
than specified in self.ncore.</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.lnprob">
<span class="sig-name descname"><span class="pre">lnprob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.lnprob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.lnprob" title="Link to this definition">¶</a></dt>
<dd><p>Log probability function used for <code class="docutils literal notranslate"><span class="pre">emcee</span></code>, which sums the prior with the surrogate model likelihood</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\ln P(\theta | x) \propto \ln P(x | \theta) + \ln P(\theta)\]</div>
</div>
<p>where ln P(x | theta) is the surrogate likelihood function and ln P(theta) is the prior function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>theta</strong> – (<em>array, required</em>) 
Array of model input parameters to evaluate model probability at.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.find_map">
<span class="sig-name descname"><span class="pre">find_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nelder-mead'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nRestarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.find_map"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.find_map" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.run_emcee">
<span class="sig-name descname"><span class="pre">run_emcee</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">like_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nwalkers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_proc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_fn_comment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">burn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_ess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.run_emcee"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.run_emcee" title="Link to this definition">¶</a></dt>
<dd><p>Sample the posterior using the emcee affine-invariant MCMC algorithm.</p>
<p>This method uses the emcee package to perform Markov Chain Monte Carlo (MCMC) 
sampling on either the trained GP surrogate model or the true likelihood function.
The affine-invariant ensemble sampler is robust and works well for a wide variety
of posterior shapes without requiring manual tuning of step sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>like_fn</strong> – (<em>callable, str, or None, optional</em>)
Likelihood function to sample. Options:
- None (default): Uses the trained GP surrogate model (self.surrogate_log_likelihood)
- “surrogate”, “gp”: Uses the GP surrogate model explicitly
- “true”: Uses the true likelihood function (self.true_log_likelihood)
- callable: Custom likelihood function with signature like_fn(theta)
Default is None.</p></li>
<li><p><strong>prior_fn</strong> – (<em>callable or None, optional</em>)
Log-prior function with signature prior_fn(theta). Should return log-probability
density. If None, uses uniform prior with bounds from self.bounds.
Default is None.</p></li>
<li><p><strong>nwalkers</strong> – (<em>int or None, optional</em>)
Number of MCMC walkers in the ensemble. Should be at least 2*ndim.
If None, defaults to 10*ndim. More walkers improve convergence but increase
computational cost. Default is None.</p></li>
<li><p><strong>nsteps</strong> – (<em>int, optional</em>)
Number of MCMC steps per walker. Total number of likelihood evaluations
will be nwalkers * nsteps. Default is 50000.</p></li>
<li><p><strong>sampler_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to emcee.EnsembleSampler constructor.
Common options include:
- ‘a’: Stretch move scale parameter (default: 2.0)
- ‘moves’: Custom proposal moves
Default is {}.</p></li>
<li><p><strong>run_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to the run_mcmc() method.
Common options include:
- ‘progress’: Show progress bar (default: True)
- ‘store’: Store chain in memory (default: True)
Default is {}.</p></li>
<li><p><strong>opt_init</strong> – (<em>bool, optional</em>)
Whether to initialize walkers near the maximum a posteriori (MAP) estimate.
If True, uses find_map() to locate starting point. If False, initializes
walkers randomly from the prior. Default is False.</p></li>
<li><p><strong>multi_proc</strong> – (<em>bool, optional</em>)
Whether to use multiprocessing with self.ncore processes. Generally
recommended for expensive likelihood evaluations. Default is True.</p></li>
<li><p><strong>prior_fn_comment</strong> – (<em>str or None, optional</em>)
Comment describing the prior function for logging purposes. If None
and prior_fn is provided, attempts to extract function name.
Default is None.</p></li>
<li><p><strong>burn</strong> – (<em>int or None, optional</em>)
Number of burn-in samples to discard from each walker. If None, 
automatically estimates burn-in using autocorrelation analysis.
Default is None.</p></li>
<li><p><strong>thin</strong> – (<em>int or None, optional</em>)
Thinning factor - keep every thin-th sample to reduce autocorrelation.
If None, automatically estimates based on autocorrelation time.
Default is None.</p></li>
<li><p><strong>samples_file</strong> – (<em>str or None, optional</em>)
If provided, saves the final samples to this file in NumPy .npz format.
Default is None.</p></li>
<li><p><strong>min_ess</strong> – (<em>int, optional</em>)
Minimum effective sample size. If the number of final samples is less than 
min_ess, will run additional sampling rounds and combine samples until the 
total number of samples exceeds min_ess. Default is 0 (no minimum required).</p></li>
</ul>
</dd>
</dl>
<section id="attributes-set">
<h3>Attributes Set<a class="headerlink" href="#attributes-set" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>sampler<span class="classifier">emcee.EnsembleSampler</span></dt><dd><p>The emcee sampler object containing full chain and metadata</p>
</dd>
<dt>emcee_samples<span class="classifier">ndarray of shape (nsamples_final, ndim)</span></dt><dd><p>Final MCMC samples after burn-in and thinning</p>
</dd>
<dt>emcee_samples_full<span class="classifier">ndarray of shape (nsteps, nwalkers, ndim)</span></dt><dd><p>Full MCMC chain before processing</p>
</dd>
<dt>emcee_samples_true<span class="classifier">ndarray of shape (nsamples_final, ndim)</span></dt><dd><p>Final samples when using true likelihood (like_fn=”true”)</p>
</dd>
<dt>emcee_samples_gp<span class="classifier">ndarray of shape (nsamples_final, ndim)</span></dt><dd><p>Final samples when using surrogate likelihood</p>
</dd>
<dt>emcee_run<span class="classifier">bool</span></dt><dd><p>Flag indicating emcee has been successfully run</p>
</dd>
<dt>emcee_runtime<span class="classifier">float</span></dt><dd><p>Wall-clock time taken for emcee sampling in seconds</p>
</dd>
<dt>nwalkers<span class="classifier">int</span></dt><dd><p>Number of walkers used</p>
</dd>
<dt>nsteps<span class="classifier">int</span></dt><dd><p>Number of steps per walker</p>
</dd>
<dt>burn<span class="classifier">int</span></dt><dd><p>Burn-in length used for final samples</p>
</dd>
<dt>thin<span class="classifier">int</span></dt><dd><p>Thinning factor used for final samples</p>
</dd>
<dt>iburn<span class="classifier">int</span></dt><dd><p>Automatically estimated burn-in length</p>
</dd>
<dt>ithin<span class="classifier">int</span></dt><dd><p>Automatically estimated thinning factor</p>
</dd>
<dt>acc_frac<span class="classifier">float</span></dt><dd><p>Mean acceptance fraction across all walkers</p>
</dd>
<dt>autcorr_time<span class="classifier">float</span></dt><dd><p>Mean autocorrelation time in steps</p>
</dd>
<dt>like_fn_name<span class="classifier">str</span></dt><dd><p>Name of likelihood function used (“true”, “surrogate”, or “likelihood”)</p>
</dd>
<dt>prior_fn_comment<span class="classifier">str</span></dt><dd><p>Description of prior function used</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>Sample surrogate model with default settings:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_emcee</span><span class="p">()</span>
</pre></div>
</div>
<p>Sample true likelihood with specific settings:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_emcee</span><span class="p">(</span><span class="n">like_fn</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">nwalkers</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nsteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
<p>Use custom prior and optimize initialization:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">log_prior</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># Custom Gaussian prior</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">theta</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_emcee</span><span class="p">(</span><span class="n">prior_fn</span><span class="o">=</span><span class="n">log_prior</span><span class="p">,</span> <span class="n">opt_init</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Run with manual burn-in and thinning:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_emcee</span><span class="p">(</span><span class="n">nsteps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">burn</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h3>
<p>emcee documentation: <a class="reference external" href="https://emcee.readthedocs.io/">https://emcee.readthedocs.io/</a>
Foreman-Mackey et al. (2013): “emcee: The MCMC Hammer”, PASP, 125, 306-312</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.run_dynesty">
<span class="sig-name descname"><span class="pre">run_dynesty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">like_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dynamic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_proc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform_comment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_ess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.run_dynesty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.run_dynesty" title="Link to this definition">¶</a></dt>
<dd><p>Sample the posterior using the dynesty nested sampling algorithm.</p>
<p>This method uses the dynesty package to perform nested sampling on either the 
trained GP surrogate model or the true likelihood function. Dynesty is particularly 
effective for estimating the Bayesian evidence and exploring multi-modal posteriors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>like_fn</strong> – (<em>callable, str, or None, optional</em>)
Likelihood function to sample. Options:
- None (default): Uses the trained GP surrogate model (self.surrogate_log_likelihood)
- “surrogate”, “gp”: Uses the GP surrogate model explicitly
- “true”: Uses the true likelihood function (self.true_log_likelihood)  
- callable: Custom likelihood function with signature like_fn(theta)
Default is None.</p></li>
<li><p><strong>prior_transform</strong> – (<em>callable or None, optional</em>)
Prior transformation function that maps from unit hypercube [0,1]^ndim
to the parameter space. Should have signature prior_transform(u) where
u is array of shape (ndim,) with values in [0,1]. If None, uses uniform
prior with bounds from self.bounds. Default is None.</p></li>
<li><p><strong>mode</strong> – (<em>{“dynamic”, “static”}, optional</em>)
Dynesty sampling mode. “dynamic” uses DynamicNestedSampler which adaptively
allocates live points, while “static” uses fixed number of live points.
Dynamic mode is generally more efficient. Default is “dynamic”.</p></li>
<li><p><strong>sampler_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to the dynesty sampler constructor.
Common options include:
- ‘nlive’: Number of live points (default: 50*ndim)
- ‘bound’: Bounding method (‘multi’, ‘single’, ‘none’)
- ‘sample’: Sampling method (‘auto’, ‘unif’, ‘rwalk’, ‘slice’, ‘rslice’, ‘hslice’)
Default is {}.</p></li>
<li><p><strong>run_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to the run_nested() method.
Common options include:
- ‘dlogz’: Target evidence uncertainty (default: 0.5)
- ‘maxiter’: Maximum number of iterations (default: 50000)
- ‘wt_kwargs’: Weight function arguments (default: {‘pfrac’: 1.0})
- ‘stop_kwargs’: Stopping criterion arguments (default: {‘pfrac’: 1.0})
Default is {}.</p></li>
<li><p><strong>multi_proc</strong> – (<em>bool, optional</em>)
Whether to use multiprocessing. If True, uses self.ncore processes.
Note that multiprocessing can sometimes be slower due to overhead.
Default is False.</p></li>
<li><p><strong>save_iter</strong> – (<em>int or None, optional</em>)
If provided, saves the sampler state every save_iter iterations to allow
for checkpointing and resuming long runs. Saves to 
‘{savedir}/dynesty_sampler_{like_fn_name}.pkl’. Default is None.</p></li>
<li><p><strong>prior_transform_comment</strong> – (<em>str or None, optional</em>)
Comment describing the prior transform for logging purposes. If None
and prior_transform is provided, attempts to extract function name.
Default is None.</p></li>
<li><p><strong>samples_file</strong> – (<em>str or None, optional</em>)
If provided, saves the final samples to this file in NumPy .npz format.
Default is None.</p></li>
<li><p><strong>min_ess</strong> – (<em>int, optional</em>)
Minimum effective sample size. If the number of final samples is less than 
min_ess, will run additional sampling rounds and combine samples until the 
total number of samples exceeds min_ess. Default is 0 (no minimum required).</p></li>
</ul>
</dd>
</dl>
<section id="id1">
<h3>Attributes Set<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>res<span class="classifier">dynesty.results.Results</span></dt><dd><p>Complete dynesty results object containing samples, weights, evidence, etc.</p>
</dd>
<dt>dynesty_samples<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Resampled posterior samples with equal weights</p>
</dd>
<dt>dynesty_samples_true<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples when using true likelihood (like_fn=”true”)</p>
</dd>
<dt>dynesty_samples_surrogate<span class="classifier">ndarray of shape (nsamples, ndim)  </span></dt><dd><p>Posterior samples when using surrogate likelihood</p>
</dd>
<dt>dynesty_run<span class="classifier">bool</span></dt><dd><p>Flag indicating dynesty has been successfully run</p>
</dd>
<dt>dynesty_runtime<span class="classifier">float</span></dt><dd><p>Wall-clock time taken for dynesty sampling in seconds</p>
</dd>
<dt>like_fn_name<span class="classifier">str</span></dt><dd><p>Name of likelihood function used (“true”, “surrogate”, or “custom”)</p>
</dd>
<dt>prior_transform_comment<span class="classifier">str</span></dt><dd><p>Description of prior transform used</p>
</dd>
</dl>
</section>
<section id="id2">
<h3>Notes<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>Dynesty is particularly well-suited for:
- Computing Bayesian evidence for model comparison
- Exploring multi-modal posteriors
- Providing robust posterior sampling without tuning</p>
<p>The default settings prioritize posterior sampling over evidence estimation
by setting pfrac=1.0, which focuses computational effort on high-likelihood
regions rather than exploring the full prior volume.</p>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h3>
<p>Sample surrogate model with default settings:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">()</span>
</pre></div>
</div>
<p>Sample true likelihood with more live points:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">(</span><span class="n">like_fn</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">sampler_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;nlive&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">})</span>
</pre></div>
</div>
<p>Use custom prior with bounds [-5, 5] for each parameter:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">my_prior</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">10</span><span class="o">*</span><span class="n">u</span> <span class="o">-</span> <span class="mi">5</span>  <span class="c1"># maps [0,1] to [-5,5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">(</span><span class="n">prior_transform</span><span class="o">=</span><span class="n">my_prior</span><span class="p">)</span>
</pre></div>
</div>
<p>Run with checkpointing every 1000 iterations:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">(</span><span class="n">save_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">run_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;maxiter&#39;</span><span class="p">:</span> <span class="mi">50000</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>References<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<p>Dynesty documentation: <a class="reference external" href="https://dynesty.readthedocs.io/">https://dynesty.readthedocs.io/</a>
Speagle (2020): “dynesty: a dynamic nested sampling package for estimating
Bayesian posteriors and evidences”, MNRAS, 493, 3132-3158</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.run_pymultinest">
<span class="sig-name descname"><span class="pre">run_pymultinest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">like_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_proc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform_comment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_clustering_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputfiles_basename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_ess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.run_pymultinest"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.run_pymultinest" title="Link to this definition">¶</a></dt>
<dd><p>Sample the posterior using the PyMultiNest nested sampling algorithm.</p>
<p>This method uses the PyMultiNest package (Python wrapper for MultiNest) to perform 
nested sampling on either the trained GP surrogate model or the true likelihood function.
MultiNest is particularly effective for multi-modal posteriors and computing Bayesian 
evidence with high accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>like_fn</strong> – (<em>callable, str, or None, optional</em>)
Likelihood function to sample. Options:
- None (default): Uses the trained GP surrogate model (self.surrogate_log_likelihood)
- “surrogate”, “gp”: Uses the GP surrogate model explicitly
- “true”: Uses the true likelihood function (self.true_log_likelihood)
- callable: Custom likelihood function with signature like_fn(theta)
Default is None.</p></li>
<li><p><strong>prior_transform</strong> – (<em>callable or None, optional</em>)
Prior transformation function that maps from unit hypercube [0,1]^ndim
to the parameter space. Should have signature prior_transform(cube) where cube
is array of shape (ndim,) with values in [0,1]. The function should modify
cube in-place. If None, uses uniform prior with bounds from self.bounds.
Default is None.</p></li>
<li><p><strong>sampler_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to pymultinest.run().
Common options include:
- ‘n_live_points’: Number of live points (default: 1000)
- ‘evidence_tolerance’: Target evidence uncertainty (default: 0.5)
- ‘sampling_efficiency’: Sampling efficiency parameter (default: 0.8)
- ‘n_iter_before_update’: Iterations before evidence/posterior update (default: 100)
- ‘null_log_evidence’: Null evidence for model comparison (default: -1e90)
- ‘max_modes’: Maximum number of modes to find (default: 100)
- ‘mode_tolerance’: Mode separation tolerance (default: -1e90)
- ‘seed’: Random seed for reproducibility (default: -1, auto)
- ‘verbose’: Verbosity level (default: True)
- ‘importance_nested_sampling’: Use importance nested sampling (default: True)
- ‘multimodal’: Enable multimodal mode detection (default: True)
- ‘const_efficiency_mode’: Use constant efficiency mode (default: False)
Default is {}.</p></li>
<li><p><strong>multi_proc</strong> – <p>(<em>bool, optional</em>)
Whether to use multiprocessing. If True, uses self.ncore processes.
MultiNest handles parallelization internally when MPI is available.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is ignored for PyMultiNest as it uses MPI for 
parallelization, not Python’s multiprocessing. When PyMultiNest
runs with MPI, other alabi functions automatically disable their
multiprocessing pools to avoid conflicts.</p>
</div>
<p>Default is True.</p>
</p></li>
<li><p><strong>prior_transform_comment</strong> – (<em>str or None, optional</em>)
Comment describing the prior function for logging purposes. If None
and prior_transform is provided, attempts to extract function name.
Default is None.</p></li>
<li><p><strong>samples_file</strong> – (<em>str or None, optional</em>)
If provided, saves the final samples to this file in NumPy .npz format.
Default is None.</p></li>
<li><p><strong>prefix</strong> – (<em>str or None, optional</em>)
Prefix for MultiNest output files. If None, uses default based on
likelihood function name and current directory. Default is None.</p></li>
<li><p><strong>resume</strong> – (<em>bool, optional</em>)
Whether to resume from previous run if output files exist.
Default is False.</p></li>
<li><p><strong>n_clustering_params</strong> – (<em>int or None, optional</em>)
Number of parameters to use for mode clustering. If None, uses all
parameters (ndim). Set to lower value if some parameters are nuisance.
Default is None.</p></li>
<li><p><strong>outputfiles_basename</strong> – (<em>str or None, optional</em>)
Base name for MultiNest output files. If None, constructs from savedir
and likelihood function name. Default is None.</p></li>
<li><p><strong>min_ess</strong> – (<em>int, optional</em>)
Minimum effective sample size. If the number of final samples is less than 
min_ess, will run additional sampling rounds and combine samples until the 
total number of samples exceeds min_ess. Default is 0 (no minimum required).</p></li>
</ul>
</dd>
</dl>
<section id="id4">
<h3>Attributes Set<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>pymultinest_samples<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples from MultiNest</p>
</dd>
<dt>pymultinest_samples_true<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples when using true likelihood (like_fn=”true”)</p>
</dd>
<dt>pymultinest_samples_surrogate<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples when using surrogate likelihood</p>
</dd>
<dt>pymultinest_weights<span class="classifier">ndarray of shape (nsamples,)</span></dt><dd><p>Sample weights from nested sampling</p>
</dd>
<dt>pymultinest_logz<span class="classifier">float</span></dt><dd><p>Log Bayesian evidence estimate</p>
</dd>
<dt>pymultinest_logz_err<span class="classifier">float</span></dt><dd><p>Uncertainty in log evidence estimate</p>
</dd>
<dt>pymultinest_run<span class="classifier">bool</span></dt><dd><p>Flag indicating PyMultiNest has been successfully run</p>
</dd>
<dt>pymultinest_runtime<span class="classifier">float</span></dt><dd><p>Wall-clock time taken for MultiNest sampling in seconds</p>
</dd>
<dt>pymultinest_analyzer<span class="classifier">pymultinest.Analyzer</span></dt><dd><p>MultiNest analyzer object for accessing detailed results</p>
</dd>
<dt>like_fn_name<span class="classifier">str</span></dt><dd><p>Name of likelihood function used (“true”, “surrogate”, or “custom”)</p>
</dd>
<dt>prior_transform_comment<span class="classifier">str</span></dt><dd><p>Description of prior function used</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PyMultiNest is particularly well-suited for:</p>
<ul class="simple">
<li><p>Multi-modal posterior exploration with automatic mode detection</p></li>
<li><p>High-accuracy Bayesian evidence computation for model comparison</p></li>
<li><p>Robust sampling without manual tuning of MCMC parameters</p></li>
<li><p>Handling complex, irregular posterior shapes</p></li>
</ul>
<p>MultiNest generates several output files including detailed posterior
samples, evidence estimates, and mode information. These files are
saved to the model’s savedir for later analysis.</p>
<p><strong>MPI and Multiprocessing Compatibility:</strong></p>
<p>PyMultiNest uses MPI for parallelization across multiple nodes/cores.
When MPI is active, alabi automatically disables Python multiprocessing
in other functions (run_emcee, run_dynesty) to prevent conflicts.
This ensures that:</p>
<ul class="simple">
<li><p>PyMultiNest can run efficiently with MPI</p></li>
<li><p>Other alabi functions fall back to serial execution when MPI is detected</p></li>
<li><p>No deadlocks or resource conflicts occur between MPI and multiprocessing</p></li>
</ul>
<p>To run PyMultiNest with MPI:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Single node, multiple cores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">()</span>  <span class="c1"># Uses OpenMP if available</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Multiple nodes with MPI (run from command line)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mpirun -n 4 python your_script.py</span>
</pre></div>
</div>
</div>
<dl class="field-list">
<dt class="field-odd">example<span class="colon">:</span></dt>
<dd class="field-odd"><p>Sample surrogate model with default settings:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">()</span>
</pre></div>
</div>
<p>Sample true likelihood with more live points:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">(</span><span class="n">like_fn</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> 
<span class="gp">... </span>                  <span class="n">sampler_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;n_live_points&#39;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">})</span>
</pre></div>
</div>
<p>Use custom prior with bounds [-10, 10] for each parameter:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">my_prior</span><span class="p">(</span><span class="n">cube</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cube</span><span class="p">)):</span>
<span class="gp">... </span>        <span class="n">cube</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span><span class="o">*</span><span class="n">cube</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">10</span>  <span class="c1"># maps [0,1] to [-10,10]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">(</span><span class="n">prior_transform</span><span class="o">=</span><span class="n">my_prior</span><span class="p">)</span>
</pre></div>
</div>
<p>Enable multimodal mode detection with high accuracy:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">(</span><span class="n">sampler_kwargs</span><span class="o">=</span><span class="p">{</span>
<span class="gp">... </span>    <span class="s1">&#39;multimodal&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;evidence_tolerance&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;max_modes&#39;</span><span class="p">:</span> <span class="mi">20</span>
<span class="gp">... </span><span class="p">})</span>
</pre></div>
</div>
<p>Run with custom output file prefix and resume capability:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_pymultinest</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;my_run_&quot;</span><span class="p">,</span> <span class="n">resume</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="id5">
<h3>References<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<p>PyMultiNest documentation: <a class="reference external" href="https://johannesbuchner.github.io/PyMultiNest/">https://johannesbuchner.github.io/PyMultiNest/</a>
Feroz et al. (2009): “MultiNest: an efficient and robust Bayesian inference
tool for cosmology and particle physics”, MNRAS, 398, 1601-1614</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.run_ultranest">
<span class="sig-name descname"><span class="pre">run_ultranest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">like_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_proc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_transform_comment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'overwrite'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_ess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.run_ultranest"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.run_ultranest" title="Link to this definition">¶</a></dt>
<dd><p>Sample the posterior using the UltraNest nested sampling algorithm.</p>
<p>This method uses the UltraNest package to perform nested sampling on either
the trained GP surrogate model or the true likelihood function. UltraNest
is a highly robust nested sampling algorithm that automatically adapts to
the problem complexity and provides reliable evidence computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>like_fn</strong> – (<em>callable, str, or None, optional</em>)
Likelihood function to sample. Options:
- None (default): Uses the trained GP surrogate model (self.surrogate_log_likelihood)
- “surrogate”, “gp”: Uses the GP surrogate model explicitly
- “true”: Uses the true likelihood function (self.true_log_likelihood)
- callable: Custom likelihood function with signature like_fn(theta)
Default is None.</p></li>
<li><p><strong>prior_transform</strong> – (<em>callable or None, optional</em>)
Prior transformation function that maps from unit hypercube [0,1]^ndim
to the parameter space. Should have signature prior_transform(cube) where
cube is array of shape (ndim,) with values in [0,1]. Must return transformed
parameters as array. If None, creates uniform prior from self.bounds.
Default is None.</p></li>
<li><p><strong>sampler_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to UltraNest ReactiveNestedSampler().
Common options include:
- ‘derived_param_names’: List of derived parameter names (default: [])
- ‘wrapped_params’: List of bool indicating circular parameters (default: None)
- ‘resume’: Resume behavior ‘resume’/’overwrite’/’subfolder’ (default: ‘subfolder’)
- ‘run_num’: Run number for subdirectory creation (default: None)
- ‘num_test_samples’: Number of test samples for validation (default: 2)
- ‘draw_multiple’: Enable dynamic point drawing (default: True)  
- ‘num_bootstraps’: Number of bootstrap samples (default: 30)
- ‘vectorized’: Whether functions accept arrays (default: False)
- ‘ndraw_min’: Minimum points to draw per iteration (default: 128)
- ‘ndraw_max’: Maximum points to draw per iteration (default: 65536)
- ‘storage_backend’: Storage format ‘hdf5’/’csv’/’tsv’ (default: ‘hdf5’)
- ‘warmstart_max_tau’: Warmstart maximum tau (default: -1)
Default is {}.</p></li>
<li><p><strong>run_kwargs</strong> – (<em>dict, optional</em>)
Additional keyword arguments passed to sampler.run().
Common options include:
- ‘update_interval_volume_fraction’: Volume fraction for region updates (default: 0.8)
- ‘update_interval_ncall’: Number of calls between updates (optional, omit for auto)
- ‘log_interval’: Iterations between status updates (optional, omit for auto)
- ‘show_status’: Show integration progress (default: True)
- ‘viz_callback’: Visualization callback function (default: False, disabled)
- ‘dlogz’: Target log-evidence uncertainty (default: 0.5)
- ‘dKL’: Target posterior uncertainty in nats (default: 0.5)
- ‘frac_remain’: Fraction of evidence remaining to terminate (default: 0.01)
- ‘Lepsilon’: Likelihood contour tolerance (default: 0.001)
- ‘min_ess’: Target effective sample size (default: 400)
- ‘max_iters’: Maximum number of iterations (optional, omit for unlimited)
- ‘max_ncalls’: Maximum number of likelihood calls (optional, omit for unlimited)
- ‘max_num_improvement_loops’: Maximum improvement loops (default: -1)
- ‘min_num_live_points’: Minimum number of live points (default: 400)
- ‘cluster_num_live_points’: Live points per cluster (default: 40)
- ‘insertion_test_zscore_threshold’: Z-score threshold for insertion test (default: 4)
- ‘insertion_test_window’: Window size for insertion test (default: 10)
- ‘region_class’: Region sampling class (optional, can be passed via kwargs)
- ‘widen_before_initial_plateau_num_warn’: Warning threshold for plateau (default: 10000)
- ‘widen_before_initial_plateau_num_max’: Maximum plateau points (optional, omit for auto)
Default is {}.</p></li>
<li><p><strong>multi_proc</strong> – (<em>bool, optional</em>)
<strong>Deprecated and ignored.</strong> This parameter is kept for backwards compatibility
but no longer has any effect. UltraNest now runs in MPI-compatible mode without
multiprocessing pools to avoid conflicts with MPI environments.
Default is False.</p></li>
<li><p><strong>prior_transform_comment</strong> – (<em>str or None, optional</em>)
Comment describing the prior transform for logging purposes. If None
and prior_transform is provided, attempts to extract function name.
Default is None.</p></li>
<li><p><strong>samples_file</strong> – (<em>str or None, optional</em>)
If provided, saves the final samples to this file in NumPy .npz format.
Default is None.</p></li>
<li><p><strong>log_dir</strong> – (<em>str or None, optional</em>)
Directory to store UltraNest output files and logs. If None, uses
a subdirectory in self.savedir. Default is None.</p></li>
<li><p><strong>resume</strong> – (<em>str, optional</em>)
Resume behavior for interrupted runs. Options:
- ‘resume’: Resume if possible, otherwise start fresh
- ‘resume-similar’: Resume with similar but not identical setup
- ‘overwrite’: Always start fresh, overwriting existing files (default)
- ‘subfolder’: Create new timestamped subfolder
Default is ‘overwrite’.</p></li>
<li><p><strong>min_ess</strong> – (<em>int, optional</em>)
Minimum effective sample size. If the number of final samples is less than 
min_ess, will run additional sampling rounds and combine samples until the 
total number of samples exceeds min_ess. Default is 0 (no minimum required).</p></li>
</ul>
</dd>
</dl>
<section id="id6">
<h3>Attributes Set<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>ultranest_results<span class="classifier">ultranest.integrator.Result</span></dt><dd><p>Complete UltraNest results object with samples, evidence, etc.</p>
</dd>
<dt>ultranest_samples<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Equally weighted posterior samples from UltraNest</p>
</dd>
<dt>ultranest_samples_true<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples when using true likelihood (like_fn=”true”)</p>
</dd>
<dt>ultranest_samples_surrogate<span class="classifier">ndarray of shape (nsamples, ndim)</span></dt><dd><p>Posterior samples when using surrogate likelihood</p>
</dd>
<dt>ultranest_weights<span class="classifier">ndarray of shape (nsamples,)</span></dt><dd><p>Sample weights (typically all equal after resampling)</p>
</dd>
<dt>ultranest_logz<span class="classifier">float</span></dt><dd><p>Log Bayesian evidence estimate</p>
</dd>
<dt>ultranest_logz_err<span class="classifier">float</span></dt><dd><p>Uncertainty in log evidence estimate</p>
</dd>
<dt>ultranest_run<span class="classifier">bool</span></dt><dd><p>Flag indicating UltraNest has been successfully run</p>
</dd>
<dt>ultranest_runtime<span class="classifier">float</span></dt><dd><p>Wall-clock time taken for UltraNest sampling in seconds</p>
</dd>
<dt>ultranest_sampler<span class="classifier">ultranest.ReactiveNestedSampler</span></dt><dd><p>UltraNest sampler object for accessing detailed information</p>
</dd>
<dt>like_fn_name<span class="classifier">str</span></dt><dd><p>Name of likelihood function used (“true”, “surrogate”, or “custom”)</p>
</dd>
<dt>prior_transform_comment<span class="classifier">str</span></dt><dd><p>Description of prior transform used</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>UltraNest is particularly well-suited for:</p>
<ul class="simple">
<li><p>Robust nested sampling without manual tuning</p></li>
<li><p>Automatic adaptation to problem complexity</p></li>
<li><p>High-dimensional and multi-modal problems</p></li>
<li><p>Reliable evidence computation for model comparison</p></li>
<li><p>Problems with complex, irregular likelihood shapes</p></li>
<li><p>MPI environments (runs in serial mode to avoid multiprocessing conflicts)</p></li>
</ul>
<p>UltraNest automatically determines the number of live points and
adapts its sampling strategy based on the problem characteristics.
It provides excellent performance across a wide range of problems
without requiring parameter tuning.</p>
<p><strong>MPI Compatibility:</strong> This function runs UltraNest in serial mode,
making it fully compatible with MPI environments. While UltraNest
itself can use MPI for parallelization, this implementation avoids
multiprocessing pools that can conflict with MPI.</p>
</div>
<dl class="field-list">
<dt class="field-odd">example<span class="colon">:</span></dt>
<dd class="field-odd"><p>Sample surrogate model with default settings:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_ultranest</span><span class="p">()</span>
</pre></div>
</div>
<p>Sample true likelihood with custom termination criteria:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_ultranest</span><span class="p">(</span><span class="n">like_fn</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> 
<span class="gp">... </span>                 <span class="n">run_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;dlogz&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;min_ess&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">})</span>
</pre></div>
</div>
<p>Use custom prior transform with bounds [-5, 5] for each parameter:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">my_prior_transform</span><span class="p">(</span><span class="n">cube</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">cube</span> <span class="o">-</span> <span class="mi">5</span>  <span class="c1"># maps [0,1] to [-5,5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_ultranest</span><span class="p">(</span><span class="n">prior_transform</span><span class="o">=</span><span class="n">my_prior_transform</span><span class="p">)</span>
</pre></div>
</div>
<p>Run with increased live points for better accuracy:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_ultranest</span><span class="p">(</span><span class="n">like_fn</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">run_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;min_num_live_points&#39;</span><span class="p">:</span> <span class="mi">800</span><span class="p">})</span>
</pre></div>
</div>
<p>Customize output directory and resume behavior:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_ultranest</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;ultranest_output&quot;</span><span class="p">,</span> 
<span class="gp">... </span>                 <span class="n">resume</span><span class="o">=</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="id7">
<h3>References<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h3>
<p>UltraNest documentation: <a class="reference external" href="https://johannesbuchner.github.io/UltraNest/">https://johannesbuchner.github.io/UltraNest/</a>
Buchner (2021): “UltraNest - a robust, general purpose Bayesian inference
library for cosmology and particle physics”, Journal of Open Source Software</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">plots</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cb_rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[None,</span> <span class="pre">None]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.plot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.plot" title="Link to this definition">¶</a></dt>
<dd><p>Generate diagnostic plots for training progress, GP performance, and MCMC results.</p>
<p>This method creates various diagnostic plots to assess the quality of the surrogate
model training, GP hyperparameter optimization, and MCMC sampling results. Plots
are automatically saved to the model’s save directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>plots</strong> – <p>(<em>list of str, optional</em>)
List of plot types to generate. Each plot requires specific data to be available
(e.g., ‘emcee_corner’ requires run_emcee() to have been called first). If None,
no plots are generated. Available options:</p>
<p><strong>Training diagnostics:</strong>
- ‘test_mse’: Mean squared error vs training iteration
- ‘test_scaled_mse’: Scaled MSE vs training iteration  
- ‘test_log_mse’: Log-scale MSE vs training iteration
- ‘gp_hyperparameters’: GP hyperparameter evolution during training
- ‘gp_train_time’: GP training time vs iteration
- ‘gp_train_corner’: Corner plot of final training samples
- ‘gp_train_scatter’: Scatter plot of training samples vs predictions</p>
<p><strong>GP visualization (2D only):</strong>
- ‘gp_fit_2D’: 2D contour plot of GP surrogate surface</p>
<p><strong>MCMC diagnostics:</strong>
- ‘emcee_corner’: Corner plot of emcee posterior samples
- ‘emcee_walkers’: Walker trajectories for emcee chains
- ‘dynesty_corner’: Corner plot of dynesty posterior samples  
- ‘dynesty_corner_kde’: KDE version of dynesty corner plot
- ‘dynesty_traceplot’: Trace plot of dynesty sampling
- ‘dynesty_runplot’: Dynesty convergence diagnostics</p>
<p><strong>Comparison plots:</strong>
- ‘mcmc_comparison’: Compare emcee and dynesty posteriors</p>
<p><strong>Convenience options:</strong>
- ‘gp_all’: Generate all available GP training plots</p>
<p>Default is None.</p>
</p></li>
<li><p><strong>show</strong> – (<em>bool, optional</em>)
Whether to display plots interactively in addition to saving them.
If False, plots are only saved to disk. Default is False.</p></li>
<li><p><strong>cb_rng</strong> – (<em>list of [float, float], optional</em>)
Colorbar range for 2D contour plots as [vmin, vmax]. If [None, None],
uses automatic range determination. Only applies to plots with colorbars
like ‘gp_fit_2D’. Default is [None, None].</p></li>
<li><p><strong>log_scale</strong> – (<em>bool, optional</em>)
Whether to use logarithmic color scale for 2D contour plots. If True,
applies matplotlib.colors.LogNorm to the colorbar. Only applies to
plots with colorbars. Default is False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None or matplotlib.figure.Figure</em>
Some individual plots may return figure objects for further customization.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>NameError</strong> – If required data for a requested plot is not available (e.g., requesting
‘emcee_corner’ before running run_emcee()).</p></li>
<li><p><strong>AttributeError</strong> – If the model has not been properly initialized or trained.</p></li>
</ul>
</dd>
</dl>
<section id="id8">
<h3>Notes<a class="headerlink" href="#id8" title="Link to this heading">¶</a></h3>
<p>Plots are automatically saved to the model’s save directory (self.savedir)
with descriptive filenames. The save directory is created if it doesn’t exist.</p>
<p>Training diagnostic plots help assess:
- Convergence of active learning process
- Quality of GP hyperparameter optimization  
- Efficiency of training sample selection</p>
<p>MCMC diagnostic plots help assess:
- Posterior sampling convergence
- Chain mixing and autocorrelation
- Comparison between different sampling methods</p>
</section>
<section id="id9">
<h3>Examples<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h3>
<p>Generate all GP training plots:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gp_all&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Create MCMC comparison plots:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_emcee</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">run_dynesty</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;emcee_corner&#39;</span><span class="p">,</span> <span class="s1">&#39;dynesty_corner&#39;</span><span class="p">,</span> <span class="s1">&#39;mcmc_comparison&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>Generate 2D GP visualization with custom colorbar:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gp_fit_2D&#39;</span><span class="p">],</span> <span class="n">cb_rng</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">log_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Show plots interactively:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;test_mse&#39;</span><span class="p">,</span> <span class="s1">&#39;gp_hyperparameters&#39;</span><span class="p">],</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.SurrogateModel.get_chain_diversity_metrics">
<span class="sig-name descname"><span class="pre">get_chain_diversity_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#SurrogateModel.get_chain_diversity_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.SurrogateModel.get_chain_diversity_metrics" title="Link to this definition">¶</a></dt>
<dd><p>Calculate diversity metrics for the combined training samples.
Useful for assessing the effectiveness of parallel chains.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="alabi.core.CachedSurrogateLikelihood">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">alabi.core.</span></span><span class="sig-name descname"><span class="pre">CachedSurrogateLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_y_cond</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#CachedSurrogateLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.CachedSurrogateLikelihood" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A picklable cached surrogate likelihood function.</p>
<p>This class creates a callable object that caches the GP computation
and can be pickled for use with multiprocessing.</p>
<dl class="py method">
<dt class="sig sig-object py" id="alabi.core.CachedSurrogateLikelihood.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_y_cond</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/core.html#CachedSurrogateLikelihood.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.core.CachedSurrogateLikelihood.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the cached surrogate likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gp_iter</strong> – Pre-computed GP object</p></li>
<li><p><strong>y_cond</strong> – Training target values</p></li>
<li><p><strong>theta_scaler</strong> – Parameter scaler object</p></li>
<li><p><strong>y_scaler</strong> – Target scaler object</p></li>
<li><p><strong>ndim</strong> – Number of dimensions</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-alabi.gp_utils">
<span id="alabi-gp-utils-module"></span><h2>alabi.gp_utils module<a class="headerlink" href="#module-alabi.gp_utils" title="Link to this heading">¶</a></h2>
<section id="gp-utils-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">gp_utils.py</span></code><a class="headerlink" href="#gp-utils-py" title="Link to this heading">¶</a></h3>
<p>Gaussian process utility functions for initializing GPs and optimizing their
hyperparameters.</p>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.gp_utils.configure_gp">
<span class="sig-prename descclassname"><span class="pre">alabi.gp_utils.</span></span><span class="sig-name descname"><span class="pre">configure_gp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_amp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_white_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">white_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/gp_utils.html#configure_gp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.gp_utils.configure_gp" title="Link to this definition">¶</a></dt>
<dd><p>Configure and initialize a Gaussian Process with robust error handling.</p>
<p>Creates a george.GP object with the specified kernel and configuration options.
Includes automatic fixes for common numerical issues such as singular matrices,
duplicate points, and poor conditioning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – (<em>array-like, shape (n_samples, n_features)</em>)
Training input locations (parameters). Must contain finite values only.</p></li>
<li><p><strong>y</strong> – (<em>array-like, shape (n_samples,)</em>)
Training target values (function evaluations). Must contain finite values only.</p></li>
<li><p><strong>kernel</strong> – (<em>george kernel object</em>)
George kernel object defining the covariance function. Common options include
ExpSquaredKernel, Matern32Kernel, Matern52Kernel.</p></li>
<li><p><strong>fit_amp</strong> – (<em>bool, optional, default=True</em>)
Whether to fit the kernel amplitude. If True, scales the kernel by the 
variance of y to improve conditioning.</p></li>
<li><p><strong>fit_mean</strong> – (<em>bool, optional, default=True</em>)
Whether to fit a constant mean function. If True, initializes mean to 
median(y) and allows optimization.</p></li>
<li><p><strong>fit_white_noise</strong> – (<em>bool, optional, default=False</em>)
Whether to fit the white noise (nugget) parameter. If True, the noise
level will be optimized during hyperparameter tuning.</p></li>
<li><p><strong>white_noise</strong> – (<em>float, optional, default=-12</em>)
Log-scale white noise parameter. Acts as regularization to prevent
singular matrices. More negative values = less noise.</p></li>
<li><p><strong>hyperparameters</strong> – (<em>array-like, optional, default=None</em>)
Pre-specified hyperparameters to set. If provided, these values are used
instead of the kernel’s default initialization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>george.GP or None</em>
Configured and computed GP object ready for predictions, or None if
configuration failed despite all attempted fixes.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If theta or y contain non-finite values (NaN or inf).</p></li>
<li><p><strong>LinAlgError</strong> – If GP computation fails due to singular covariance matrix, automatically
attempts several fixes before giving up.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.gp_utils.optimize_gp">
<span class="sig-prename descclassname"><span class="pre">alabi.gp_utils.</span></span><span class="sig-name descname"><span class="pre">optimize_gp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gp_hyper_prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l-bfgs-b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/gp_utils.html#optimize_gp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.gp_utils.optimize_gp" title="Link to this definition">¶</a></dt>
<dd><p>Optimize Gaussian Process hyperparameters by maximizing marginal likelihood.</p>
<p>Performs hyperparameter optimization for a Gaussian Process using scipy’s
minimize function. Supports multiple optimization restarts and automatically
selects the result with highest marginal likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gp</strong> – (<em>george.GP</em>)
Configured Gaussian Process object. Should be computed with training data.</p></li>
<li><p><strong>_theta</strong> – (<em>array-like, shape (n_samples, n_features)</em>)
Training input locations (parameters). Will be squeezed if 1D.</p></li>
<li><p><strong>_y</strong> – (<em>array-like, shape (n_samples,)</em>)
Training target values (function evaluations). Will be squeezed if 1D.</p></li>
<li><p><strong>gp_hyper_prior</strong> – (<em>callable</em>)
Prior function for hyperparameters. Should return log-probability density
for given hyperparameter vector. Used to constrain optimization.</p></li>
<li><p><strong>p0</strong> – (<em>array-like, shape (n_restarts, n_hyperparams) or (n_hyperparams,)</em>)
Initial guesses for hyperparameter optimization. If 2D, performs multiple
restarts with different initializations.</p></li>
<li><p><strong>bounds</strong> – (<em>list of tuples, optional, default=None</em>)
Bounds for hyperparameter optimization as [(min, max), …]. Only used
for methods that support bounds (e.g., ‘l-bfgs-b’).</p></li>
<li><p><strong>method</strong> – <p>(<em>str, optional, default=”l-bfgs-b”</em>)
Scipy optimization method. Supported methods:</p>
<ul>
<li><p>’l-bfgs-b’: L-BFGS-B with bounds support (default)</p></li>
<li><p>’newton-cg’: Newton-CG with gradients</p></li>
<li><p>’bfgs’: BFGS (no bounds support)</p></li>
<li><p>’powell’: Powell method (derivative-free)</p></li>
</ul>
</p></li>
<li><p><strong>optimizer_kwargs</strong> – (<em>dict, optional, default=None</em>)
Additional keyword arguments passed to scipy.optimize.minimize.
If None, uses method-specific defaults optimized for GP optimization.</p></li>
<li><p><strong>max_iter</strong> – (<em>int, optional, default=50</em>)
Maximum number of iterations for optimization. Used as default in
optimizer_kwargs if not specified.</p></li>
<li><p><strong>regularize</strong> – (<em>bool, optional, default=False</em>)
Whether to apply Hvarfner dimensionality-scaled regularization (Equation 4
from “Vanilla Bayesian Optimization Performs Great in High Dimensions”).
When True, lengthscale priors are scaled as LogNormal(μ_0 + log(√d), σ_0).</p></li>
<li><p><strong>mu_0</strong> – (<em>float, optional, default=0.0</em>)
Base location parameter for Hvarfner regularization. Only used if regularize=True.</p></li>
<li><p><strong>sigma_0</strong> – (<em>float, optional, default=1.0</em>)
Scale parameter for Hvarfner regularization. Only used if regularize=True.</p></li>
<li><p><strong>lengthscale_indices</strong> – (<em>list of int, optional, default=None</em>)
Indices in the parameter vector corresponding to lengthscale parameters.
Only used if regularize=True. If None, attempts to infer from kernel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>george.GP or None</em>
GP object with optimized hyperparameters, or None if optimization failed.
The returned GP is recomputed with optimal hyperparameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.gp_utils.optimize_gp_kfold_cv">
<span class="sig-prename descclassname"><span class="pre">alabi.gp_utils.</span></span><span class="sig-name descname"><span class="pre">optimize_gp_kfold_cv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparameter_candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_scaler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stage2_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stage2_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stage3_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stage3_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted_mse_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'exponential'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted_mse_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/gp_utils.html#optimize_gp_kfold_cv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.gp_utils.optimize_gp_kfold_cv" title="Link to this definition">¶</a></dt>
<dd><p>Optimize Gaussian Process hyperparameters using k-fold cross-validation.</p>
<p>This function evaluates different hyperparameter configurations using k-fold 
cross-validation to select the configuration that generalizes best to unseen data.
This approach helps prevent overfitting compared to standard marginal likelihood
maximization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gp</strong> – (<em>george.GP</em>)
Configured Gaussian Process object template. Will be copied for each CV fold.</p></li>
<li><p><strong>_theta</strong> – (<em>array-like, shape (n_samples, n_features)</em>)
Training input locations (parameters). Must have at least k_folds samples.</p></li>
<li><p><strong>_y</strong> – (<em>array-like, shape (n_samples,)</em>)
Training target values (function evaluations). Must match _theta length.</p></li>
<li><p><strong>gp_hyper_prior</strong> – (<em>callable</em>)
Prior function for hyperparameters. Should return log-probability density
for given hyperparameter vector. Used to constrain search space.</p></li>
<li><p><strong>hyperparameter_candidates</strong> – (<em>array-like, shape (n_candidates, n_hyperparams)</em>)
Array of hyperparameter vectors to evaluate via cross-validation.
Each row represents one hyperparameter configuration to test.</p></li>
<li><p><strong>k_folds</strong> – (<em>int, optional, default=5</em>)
Number of folds for cross-validation. Must be &gt;= 2 and &lt;= n_samples.
Common choices: 5 or 10 for good bias-variance tradeoff.</p></li>
<li><p><strong>scoring</strong> – <p>(<em>str, optional, default=’mse’</em>)
Scoring metric for cross-validation. Supported options:</p>
<ul>
<li><p>’mse’: Mean Squared Error (lower is better)</p></li>
<li><p>’mae’: Mean Absolute Error (lower is better)</p></li>
<li><p>’r2’: R-squared coefficient (higher is better)</p></li>
<li><p>’weighted_mse’: Weighted MSE giving higher weight to high-probability regions</p></li>
</ul>
</p></li>
<li><p><strong>pool</strong> – (<em>multiprocessing.Pool, optional, default=None</em>)
Multiprocessing pool for parallel evaluation of hyperparameter candidates.
If None, evaluation runs sequentially. If provided, candidates are 
evaluated in parallel using the pool’s worker processes.</p></li>
<li><p><strong>stage2_candidates</strong> – (<em>int, optional, default=None</em>)
Number of candidates for stage 2 grid search. If None, uses 
len(hyperparameter_candidates) // 2.</p></li>
<li><p><strong>stage2_width</strong> – (<em>float, optional, default=0.5</em>)
Width factor for stage 2 search around best parameters.
Smaller values = tighter search, larger values = wider search.</p></li>
<li><p><strong>stage3_candidates</strong> – (<em>int, optional, default=None</em>)
Number of candidates for stage 3 ultra-fine search. If None, uses 
max(stage2_candidates // 2, 3).</p></li>
<li><p><strong>stage3_width</strong> – (<em>float, optional, default=0.2</em>)
Width factor for stage 3 search around stage 2 best parameters.
Should be smaller than stage2_width for finer refinement.</p></li>
<li><p><strong>weighted_mse_method</strong> – (<em>str, optional, default=’exponential’</em>)
Weighting method for weighted_mse scoring. Options:
- ‘exponential’: w = exp(y_true / temperature)
- ‘linear’: w = y_true - min(y_true) + epsilon  
- ‘softmax’: w = softmax(y_true / temperature)
- ‘rank’: w based on rank order of y_true</p></li>
<li><p><strong>weighted_mse_factor</strong> – (<em>float, optional, default=1.0</em>)
Temperature parameter for exponential/softmax weighting.
Lower values emphasize high-probability regions more strongly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>best_gp</strong> (<em>george.GP</em>) – GP with optimal hyperparameters set</p></li>
<li><p><strong>best_hyperparams</strong> (<em>array</em>) – Best hyperparameter vector</p></li>
<li><p><strong>cv_results</strong> (<em>dict</em>) – Detailed CV results with scores and statistics</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If insufficient data, invalid parameters, or no valid hyperparameters</p></li>
<li><p><strong>RuntimeError</strong> – If all hyperparameter evaluations fail</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.gp_utils.regularization_term">
<span class="sig-prename descclassname"><span class="pre">alabi.gp_utils.</span></span><span class="sig-name descname"><span class="pre">regularization_term</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/gp_utils.html#regularization_term"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.gp_utils.regularization_term" title="Link to this definition">¶</a></dt>
<dd><p>Compute the regularization term (negative log prior) from Hvafner 2024 Equation 4.</p>
<p>This implements the dimensionality-scaled LogNormal prior:
p(ℓ_i | d) = LogNormal(μ_0 + log(√d), σ_0)</p>
<p>The regularization term is -log p(ℓ | d) = -Σ log p(ℓ_i | d)</p>
<section id="parameters">
<h3>Parameters:<a class="headerlink" href="#parameters" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>mu_0<span class="classifier">float, default=0.0</span></dt><dd><p>The base location parameter for the 1D LogNormal prior</p>
</dd>
<dt>sigma_0<span class="classifier">float, default=1.0</span></dt><dd><p>The scale parameter for the LogNormal prior</p>
</dd>
</dl>
</section>
<section id="returns">
<h3>Returns:<a class="headerlink" href="#returns" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>float</dt><dd><p>The regularization term (negative log prior)</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.gp_utils.regularization_gradient">
<span class="sig-prename descclassname"><span class="pre">alabi.gp_utils.</span></span><span class="sig-name descname"><span class="pre">regularization_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/gp_utils.html#regularization_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.gp_utils.regularization_gradient" title="Link to this definition">¶</a></dt>
<dd><p>Compute the gradient of the regularization term with respect to lengthscales.</p>
<section id="id10">
<h3>Parameters:<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>lengthscales<span class="classifier">array-like, shape (d,)</span></dt><dd><p>The lengthscale parameters for each dimension</p>
</dd>
<dt>d<span class="classifier">int</span></dt><dd><p>The dimensionality of the problem</p>
</dd>
<dt>mu_0<span class="classifier">float, default=0.0</span></dt><dd><p>The base location parameter for the 1D LogNormal prior</p>
</dd>
<dt>sigma_0<span class="classifier">float, default=1.0</span></dt><dd><p>The scale parameter for the LogNormal prior</p>
</dd>
</dl>
</section>
<section id="id11">
<h3>Returns:<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>ndarray, shape (d,)</dt><dd><p>The gradient of the regularization term with respect to each lengthscale</p>
</dd>
</dl>
</section>
</dd></dl>

</section>
<section id="module-alabi.mcmc_utils">
<span id="alabi-mcmc-utils-module"></span><h2>alabi.mcmc_utils module<a class="headerlink" href="#module-alabi.mcmc_utils" title="Link to this heading">¶</a></h2>
<section id="mcmc-utils-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">mcmc_utils.py</span></code><a class="headerlink" href="#mcmc-utils-py" title="Link to this heading">¶</a></h3>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.mcmc_utils.estimate_burnin">
<span class="sig-prename descclassname"><span class="pre">alabi.mcmc_utils.</span></span><span class="sig-name descname"><span class="pre">estimate_burnin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">est_burnin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thin_chains</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/mcmc_utils.html#estimate_burnin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.mcmc_utils.estimate_burnin" title="Link to this definition">¶</a></dt>
<dd><p>Estimate the integrated autocorrelation length on the MCMC chain associated
with an emcee sampler object. With the integrated autocorrelation length,
we can then estimate the burn-in length for the MCMC chain. This procedure
follows the example outlined here:
<a class="reference external" href="https://emcee.readthedocs.io/en/stable/tutorials/autocorr/">https://emcee.readthedocs.io/en/stable/tutorials/autocorr/</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sampler</strong> – (<em>emcee.EnsembleSampler, optional</em>)
emcee MCMC sampler object/backend handler, given a complete chain</p></li>
<li><p><strong>est_burnin</strong> – (<em>bool, optional</em>)
Estimate burn-in time using integrated autocorrelation time
heuristic.  Defaults to True. In general, we recommend users
inspect the chains and calculate the burnin after the fact to ensure
convergence, but this function works pretty well.</p></li>
<li><p><strong>thin_chains</strong> – (<em>bool, optional</em>)
Whether or not to thin chains.  Useful if running long chains.
Defaults to True.  If true, estimates a thin cadence
via int(0.5*np.min(tau)) where tau is the intergrated autocorrelation
time.</p></li>
<li><p><strong>verbose</strong> – (<em>bool, optional</em>)
Output all the diagnostics? Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns iburn<span class="colon">:</span></dt>
<dd class="field-even"><p>(<em>int</em>)
burn-in index estimate.  If est_burnin == False, returns 0.</p>
</dd>
<dt class="field-odd">Returns ithin<span class="colon">:</span></dt>
<dd class="field-odd"><p>(<em>int</em>)
thin cadence estimate.  If thin_chains == False, returns 1.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-alabi.utility">
<span id="alabi-utility-module"></span><h2>alabi.utility module<a class="headerlink" href="#module-alabi.utility" title="Link to this heading">¶</a></h2>
<section id="utility-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">utility.py</span></code><a class="headerlink" href="#utility-py" title="Link to this heading">¶</a></h3>
<p>Utility functions in terms of usefulness, e.g. minimizing GP utility functions
or computing KL divergences, and the GP utility functions, e.g. the bape utility.</p>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.agp_utility">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">agp_utility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#agp_utility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.agp_utility" title="Link to this definition">¶</a></dt>
<dd><p>Compute the AGP (Adaptive Gaussian Process) utility function based on posterior entropy.</p>
<p>AGP is an information-theoretic acquisition function that measures the entropy
of the Gaussian Process posterior distribution. It balances the GP mean prediction
with the uncertainty (variance), preferring regions with high predicted values
and high uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – (<em>array-like of shape (ndim,)</em>)
Parameter values at which to evaluate the utility function.</p></li>
<li><p><strong>y</strong> – (<em>array-like of shape (nsamples,)</em>)
Observed function values at training points, used to condition the GP.</p></li>
<li><p><strong>gp</strong> – (<em>george.GP</em>)
Trained Gaussian Process model. The GP will be computed if not already done.</p></li>
<li><p><strong>bounds</strong> – (<em>array-like of shape (ndim, 2)</em>)
Parameter bounds as [(min, max), …] for each dimension. Used to check
if theta is within the prior support.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>float</em>
Negative AGP utility value. The negative is used so that minimizing
this function is equivalent to maximizing the actual utility.</p>
</dd>
</dl>
<p><strong>Notes</strong></p>
<p>The AGP utility function is defined as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[u(\theta) = \mu(\theta) + \frac{1}{2} \ln(2\pi e \sigma^2(\theta))\]</div>
</div>
<p>This represents the entropy of the posterior predictive distribution at θ.
The utility encourages sampling where:
- The mean prediction μ(θ) is high (exploitation)
- The predictive variance σ²(θ) is high (exploration)</p>
<p>AGP provides a different balance compared to other acquisition functions:
- More exploitative than BAPE (focuses on high mean regions)
- Less optimization-focused than Expected Improvement
- Naturally balances exploration and exploitation through entropy</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If the utility computation results in invalid values (e.g., negative variance).</p>
</dd>
</dl>
<p><strong>Examples</strong></p>
<p>Evaluate AGP utility at a test point:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">theta_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">])</span>
<span class="n">utility</span> <span class="o">=</span> <span class="n">agp_utility</span><span class="p">(</span><span class="n">theta_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>References</strong></p>
<p>Wang &amp; Li (2017): “Adaptive Gaussian Process Approximation for Bayesian 
Inference with Expensive Likelihood Functions”, Neural Computation, 30, 3072-3094.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.bape_utility">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">bape_utility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#bape_utility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.bape_utility" title="Link to this definition">¶</a></dt>
<dd><p>Compute the BAPE (Bayesian Active Posterior Estimation) utility function.</p>
<p>BAPE is an active learning acquisition function designed for posterior exploration
rather than optimization. It identifies regions where the GP variance is high
relative to the mean, promoting exploration of the parameter space. The utility
is computed in log-form for numerical stability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> (<em>array-like of shape (ndim,)</em>) – Parameter values at which to evaluate the utility function.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape (nsamples,)</em>) – Observed function values at training points, used to condition the GP.</p></li>
<li><p><strong>gp</strong> (<em>george.GP</em>) – Trained Gaussian Process model. Must have been computed (gp.computed=True).</p></li>
<li><p><strong>bounds</strong> (<em>array-like of shape (ndim, 2)</em>) – Parameter bounds as [(min, max), …] for each dimension. Used to check
if theta is within the prior support.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Negative log-BAPE utility value. The negative is used so that minimizing
this function is equivalent to maximizing the actual utility.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>float</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The BAPE utility function is defined as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[u(\theta) = e^{2\mu(\theta) + \sigma^2(\theta)} \left(e^{\sigma^2(\theta)} - 1 \right)\]</div>
</div>
<p>This function returns the negative logarithm of the utility for numerical stability:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[-\log u(\theta) = -\left(2\mu(\theta) + \sigma^2(\theta) + \log(e^{\sigma^2(\theta)} - 1)\right)\]</div>
</div>
<p>BAPE is particularly effective for:</p>
<ul class="simple">
<li><p>Exploring multi-modal posteriors</p></li>
<li><p>Reducing uncertainty in posterior estimates</p></li>
<li><p>Active learning when the goal is posterior characterization</p></li>
</ul>
<p>Unlike optimization-focused acquisitions (e.g., Expected Improvement), BAPE
prioritizes exploration over exploitation, making it less suitable for finding
global optima but excellent for posterior mapping.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If the utility computation results in invalid values (e.g., negative variance).</p></li>
<li><p><strong>RuntimeError</strong> – If the GP has not been computed before calling this function.</p></li>
</ul>
</dd>
</dl>
<p><strong>Examples</strong></p>
<p>Evaluate BAPE utility at a test point:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">theta_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">utility</span> <span class="o">=</span> <span class="n">bape_utility</span><span class="p">(</span><span class="n">theta_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>References</strong></p>
<p>Kandasamy et al. (2015): “Query efficient posterior estimation in scientific 
experiments via Bayesian active learning”, Artificial Intelligence, 243, 45-56.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.jones_utility">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">jones_utility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_gp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_best</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zeta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#jones_utility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.jones_utility" title="Link to this definition">¶</a></dt>
<dd><p>Compute the Expected Improvement (EI) acquisition function.</p>
<p>This function implements the Expected Improvement criterion from Jones et al. (1998),
which balances exploitation (sampling where the mean is high) with exploration
(sampling where the uncertainty is high). Unlike BAPE, this acquisition function
is designed specifically for global optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> (<em>array-like of shape (ndim,)</em>) – Parameter values at which to evaluate the utility function.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape (nsamples,)</em>) – Observed function values at training points. The maximum value is used
as the current best (f_best).</p></li>
<li><p><strong>gp</strong> (<em>george.GP</em>) – Trained Gaussian Process model. Must have been computed (gp.computed=True).</p></li>
<li><p><strong>bounds</strong> (<em>array-like of shape (ndim, 2)</em>) – Parameter bounds as [(min, max), …] for each dimension. Used to check
if theta is within the prior support.</p></li>
<li><p><strong>zeta</strong> (<em>float, optional</em>) – <p>Exploration parameter controlling the trade-off between exploitation
and exploration. Larger values promote more exploration:</p>
<ul>
<li><p>zeta = 0: Pure exploitation (greedy)</p></li>
<li><p>zeta &gt; 0: Balanced exploration/exploitation</p></li>
<li><p>zeta &gt;&gt; 0: Pure exploration</p></li>
</ul>
<p>Default is 0.01.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Negative Expected Improvement value. The negative is used so that minimizing
this function is equivalent to maximizing the Expected Improvement.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>float</em></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Expected Improvement is defined as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[EI(\theta) = \mathbb{E}[\max(f(\theta) - f_{\text{best}} - \zeta, 0)]\]</div>
</div>
<p>where f_best is the current best observed value. For a Gaussian predictive
distribution with mean μ and variance σ², this becomes:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[EI(\theta) = (\mu - f_{\text{best}} - \zeta) \Phi(z) + \sigma \phi(z)\]</div>
</div>
<p>where z = (μ - f_best - ζ)/σ, Φ is the standard normal CDF, and φ is the
standard normal PDF.</p>
<p>Expected Improvement is particularly effective for:</p>
<ul class="simple">
<li><p>Global optimization problems</p></li>
<li><p>Finding the maximum of expensive functions</p></li>
<li><p>Balancing local and global search</p></li>
</ul>
<p>Compared to BAPE, Expected Improvement focuses on exploitation (finding optima)
rather than exploration (mapping the entire posterior).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If the utility computation results in invalid values.</p></li>
<li><p><strong>RuntimeError</strong> – If the GP has not been computed before calling this function.</p></li>
</ul>
</dd>
</dl>
<p><strong>References</strong></p>
<p>Jones et al. (1998): “Efficient global optimization of expensive black-box 
functions”, Journal of Global Optimization, 13, 455-492.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.assign_utility">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">assign_utility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">algorithm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#assign_utility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.assign_utility" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.minimize_objective">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">minimize_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nopt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l-bfgs-b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_obj_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#minimize_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.minimize_objective" title="Link to this definition">¶</a></dt>
<dd><p>Find the global minimum of an acquisition function using multiple restarts.</p>
<p>This function optimizes acquisition functions (BAPE, Jones/EI, etc.) to select
the next point for active learning. Multiple optimization restarts with different
initial points help avoid local minima, which is crucial for acquisition function
optimization where the landscape can be highly multi-modal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obj_fn</strong> (<em>callable</em>) – Objective function to minimize. Should have signature obj_fn(theta) and
return a scalar value. Typically an acquisition function like BAPE or EI.</p></li>
<li><p><strong>grad_obj_fn</strong> (<em>callable or None, optional</em>) – Gradient of the objective function. Should have signature grad_obj_fn(theta)
and return array of shape (ndim,). If None, uses finite differences.</p></li>
<li><p><strong>bounds</strong> (<em>array-like of shape (ndim, 2)</em>) – Parameter bounds as [(min, max), …] for each dimension. Used both
for optimization constraints and generating initial points.</p></li>
<li><p><strong>nopt</strong> (<em>int, optional</em>) – Number of optimization restarts with different initial points. More
restarts increase the chance of finding the global minimum but increase
computational cost. Default is 1.</p></li>
<li><p><strong>method</strong> (<em>str, optional</em>) – <p>Scipy optimization method to use. Common choices:</p>
<ul>
<li><p>”l-bfgs-b”: Quasi-Newton with bounds (default, works well with gradients)</p></li>
<li><p>”nelder-mead”: Simplex method (gradient-free, robust)</p></li>
<li><p>”tnc”: Truncated Newton with bounds</p></li>
<li><p>”slsqp”: Sequential Least Squares Programming</p></li>
</ul>
<p>Default is “l-bfgs-b”.</p>
</p></li>
<li><p><strong>ps</strong> (<em>callable or None, optional</em>) – Prior sampling function with signature ps(nsample=1). Used to generate
initial points for optimization restarts. If None, uses uniform sampling
within bounds. Default is None.</p></li>
<li><p><strong>options</strong> (<em>dict or None, optional</em>) – <p>Additional options passed to scipy.optimize.minimize. Common options:</p>
<ul>
<li><p>”max_iter”: Maximum iterations (default: 50)</p></li>
<li><p>”ftol”: Function tolerance for convergence</p></li>
<li><p>”gtol”: Gradient tolerance for convergence</p></li>
</ul>
<p>Default is {“max_iter”: 50}.</p>
</p></li>
<li><p><strong>grad_obj_fn</strong> – Gradient of the objective function. If provided, can significantly
speed up optimization for methods like l-bfgs-b. Default is None (use finite differences).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>theta_best</strong> (<em>ndarray of shape (ndim,)</em>) – Parameter values that minimize the objective function.</p></li>
<li><p><strong>obj_best</strong> (<em>float</em>) – Minimum objective function value achieved.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tuple</em></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – If no valid solutions are found after all optimization attempts.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.prior_sampler">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">prior_sampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'uniform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#prior_sampler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.prior_sampler" title="Link to this definition">¶</a></dt>
<dd><p>Sample from parameter space using various quasi-random sampling methods.</p>
<p>This function generates samples within specified bounds using different sampling
strategies from the scikit-optimize library. It provides a unified interface to
various space-filling designs commonly used in Bayesian optimization and 
surrogate modeling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – (<em>array-like of shape (ndim, 2)</em>)
Array of (min, max) bounds for each parameter dimension. Each row specifies
the lower and upper bounds for one parameter.</p></li>
<li><p><strong>nsample</strong> – (<em>int, optional</em>)
Number of samples to generate. Default is 1.</p></li>
<li><p><strong>sampler</strong> – <p>(<em>{‘uniform’, ‘sobol’, ‘lhs’, ‘halton’, ‘hammersly’, ‘grid’}, optional</em>)
Sampling method to use:</p>
<ul>
<li><p>’uniform’: random uniform sampling</p></li>
<li><p>’sobol’: Sobol sequence (quasi-random, good space-filling)</p></li>
<li><p>’lhs’: Latin Hypercube Sampling (stratified sampling)</p></li>
<li><p>’halton’: Halton sequence (quasi-random, low discrepancy)</p></li>
<li><p>’hammersly’: Hammersley sequence (quasi-random)</p></li>
<li><p>’grid’: Regular grid sampling</p></li>
</ul>
<p>Default is ‘uniform’.</p>
</p></li>
<li><p><strong>random_state</strong> – (<em>int, RandomState instance or None, optional</em>)
Random state for reproducible sampling. If None, uses a different random
seed each time to avoid clustering. Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray of shape (nsample, ndim)</em>
Array of parameter samples within the specified bounds.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If an invalid sampler method is specified.</p>
</dd>
</dl>
<p><strong>Notes</strong></p>
<p>Quasi-random samplers (sobol, halton, hammersley) provide better space-filling
properties than pseudo-random uniform sampling, which is beneficial for:
- Initial design of experiments
- Training surrogate models
- Global optimization</p>
<p>Latin Hypercube Sampling ensures each parameter dimension is stratified,
providing good marginal coverage even with small sample sizes.</p>
<p>For optimization starting points, consider using ‘sobol’ or ‘lhs’ instead of
‘uniform’ to avoid clustering issues when generating single samples repeatedly.</p>
<p><strong>Examples</strong></p>
<p>Generate uniform random samples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">prior_sampler</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">nsample</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (5, 2)</span>
</pre></div>
</div>
<p>Use Sobol sequence for better space-filling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">prior_sampler</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">nsample</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="s1">&#39;sobol&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Latin Hypercube Sampling for stratified design:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">prior_sampler</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">nsample</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="s1">&#39;lhs&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>References</strong></p>
<p>For more information on sampling methods, see:
<a class="reference external" href="https://scikit-optimize.github.io/stable/auto_examples/sampler/initial-sampling-method.html">https://scikit-optimize.github.io/stable/auto_examples/sampler/initial-sampling-method.html</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.prior_sampler_normal">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">prior_sampler_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#prior_sampler_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.prior_sampler_normal" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.lnprior_uniform">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">lnprior_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#lnprior_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.lnprior_uniform" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate log-probability density of uniform prior distribution.</p>
<p>This function computes the log-probability density for a uniform (flat)
prior distribution within specified bounds. Points outside the bounds
receive log-probability of negative infinity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – (<em>array-like of shape (ndim,) or float</em>)
Parameter values at which to evaluate the log-prior. For scalar input,
assumes 1D parameter space.</p></li>
<li><p><strong>bounds</strong> – (<em>array-like of shape (ndim, 2)</em>)
Parameter bounds as [(min, max), …] for each dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>float</em>
Log-probability density. Returns 0.0 if all parameters are within bounds,
-np.inf if any parameter is outside bounds.</p>
</dd>
</dl>
<p><strong>Notes</strong></p>
<p>For a uniform distribution on [a, b], the probability density is 1/(b-a)
and the log-probability density is -log(b-a). However, this function 
returns 0.0 for in-bounds points since constant offsets don’t affect
relative probabilities in MCMC sampling.</p>
<p><strong>Examples</strong></p>
<p>Check if point is within bounds:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">lnp</span> <span class="o">=</span> <span class="n">lnprior_uniform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>  <span class="c1"># Returns 0.0</span>
</pre></div>
</div>
<p>Point outside bounds:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>  <span class="c1"># First parameter out of bounds</span>
<span class="n">lnp</span> <span class="o">=</span> <span class="n">lnprior_uniform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>  <span class="c1"># Returns -inf</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.prior_transform_uniform">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">prior_transform_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#prior_transform_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.prior_transform_uniform" title="Link to this definition">¶</a></dt>
<dd><p>Transform uniform random variables to parameter space with specified bounds.</p>
<p>This function implements the inverse CDF transformation for uniform distributions,
mapping from the unit hypercube [0,1]^ndim to the parameter space with given bounds.
It is commonly used in nested sampling algorithms like dynesty and UltraNest.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – (<em>array-like</em>)
Random variables uniformly distributed on [0,1]. Can be:
- 1D array of shape (ndim,) for a single parameter vector
- 2D array of shape (nsamples, ndim) for multiple parameter vectors</p></li>
<li><p><strong>bounds</strong> – (<em>array-like of shape (ndim, 2)</em>)
Parameter bounds as [(min, max), …] for each dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em>
Transformed parameter values within the specified bounds.
- If input is 1D: returns 1D array of shape (ndim,)
- If input is 2D: returns 2D array of shape (nsamples, ndim)</p>
</dd>
</dl>
<p><strong>Notes</strong></p>
<p>The transformation for each dimension i is:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\theta'_i = (b_{i,\text{max}} - b_{i,\text{min}}) \theta_i + b_{i,\text{min}}\]</div>
</div>
<p>where b_{i,min} and b_{i,max} are the bounds for dimension i.</p>
<p>This is the inverse of the uniform CDF, mapping uniform random variables
on [0,1] to uniform random variables on [a,b].</p>
<p><strong>Examples</strong></p>
<p>Transform single parameter vector:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">theta_unit</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>  <span class="c1"># Single vector</span>
<span class="n">theta_params</span> <span class="o">=</span> <span class="n">prior_transform_uniform</span><span class="p">(</span><span class="n">theta_unit</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta_params</span><span class="p">)</span>  <span class="c1"># [-1.0, 8.0]</span>
</pre></div>
</div>
<p>Transform multiple parameter vectors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">theta_unit</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]]</span>  <span class="c1"># Multiple vectors</span>
<span class="n">theta_params</span> <span class="o">=</span> <span class="n">prior_transform_uniform</span><span class="p">(</span><span class="n">theta_unit</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta_params</span><span class="p">)</span>  <span class="c1"># [[-1.0, 8.0], [0.0, 2.0]]</span>
</pre></div>
</div>
<p>Use with nested sampling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">my_prior_transform</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">prior_transform_uniform</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)</span>
<span class="c1"># Pass to dynesty/UltraNest sampler</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.lnprior_normal">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">lnprior_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#lnprior_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.lnprior_normal" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.prior_transform_normal">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">prior_transform_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#prior_transform_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.prior_transform_normal" title="Link to this definition">¶</a></dt>
<dd><p>Transform uniform random variables to parameter space with mixed prior distributions.</p>
<p>This function implements prior transformations supporting both uniform and Gaussian
priors for different parameters. It maps from the unit hypercube [0,1]^ndim to
the parameter space, handling each dimension according to its specified prior type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – (<em>array-like</em>)
Random variables uniformly distributed on [0,1]. Can be:
- 1D array of shape (ndim,) for a single parameter vector
- 2D array of shape (nsamples, ndim) for multiple parameter vectors</p></li>
<li><p><strong>bounds</strong> – (<em>array-like of shape (ndim, 2)</em>)
Parameter bounds as [(min, max), …] for each dimension. Used for uniform priors.</p></li>
<li><p><strong>data</strong> – (<em>list of tuples</em>)
Prior specification for each dimension as [(mean, std), …]. 
- If data[i] = (None, None): use uniform prior with bounds[i]
- If data[i] = (mean, std): use Gaussian prior with specified mean and standard deviation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em>
Transformed parameter values according to their prior distributions.
- If input is 1D: returns 1D array of shape (ndim,)
- If input is 2D: returns 2D array of shape (nsamples, ndim)</p>
</dd>
</dl>
<p><strong>Notes</strong></p>
<p>For uniform priors (when data[i][0] is None):</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\theta'_i = (b_{i,\text{max}} - b_{i,\text{min}}) x_i + b_{i,\text{min}}\]</div>
</div>
<p>For Gaussian priors (when data[i] = (μ, σ)):</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\theta'_i = \Phi^{-1}(x_i; \mu_i, \sigma_i)\]</div>
</div>
<p>where Φ^{-1} is the inverse normal CDF (percent-point function).</p>
<p><strong>Examples</strong></p>
<p>Mixed uniform and Gaussian priors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)]</span>  <span class="c1"># uniform, then Gaussian(5, 1)</span>
<span class="n">x_unit</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">]</span>  <span class="c1"># Single vector</span>
<span class="n">x_params</span> <span class="o">=</span> <span class="n">prior_transform_normal</span><span class="p">(</span><span class="n">x_unit</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_params</span><span class="p">)</span>  <span class="c1"># [0.0, ~6.0] (second value from normal inverse CDF)</span>
</pre></div>
</div>
<p>Vectorized transformation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_unit</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.16</span><span class="p">]]</span>  <span class="c1"># Multiple vectors</span>
<span class="n">x_params</span> <span class="o">=</span> <span class="n">prior_transform_normal</span><span class="p">(</span><span class="n">x_unit</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="c1"># Returns 2D array with transformed parameters</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">BetaWarpingFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Swersky et al. 2017 Beta CDF warping function for sklearn FunctionTransformer.</p>
<p>Note: This transformer must be refit when new data extends beyond the 
original data range to update the internal MinMaxScaler bounds.</p>
<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction.fit" title="Link to this definition">¶</a></dt>
<dd><p>Fit the MinMaxScaler to the data, establishing the data range bounds.</p>
<p>This updates the internal min/max values used for scaling. Should be
called whenever new data extends beyond the previous range.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction.transform" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction.fit_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction.fit_transform" title="Link to this definition">¶</a></dt>
<dd><p>Fit and transform in one step.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.BetaWarpingFunction.inverse_transform">
<span class="sig-name descname"><span class="pre">inverse_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#BetaWarpingFunction.inverse_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.BetaWarpingFunction.inverse_transform" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.utility.beta_warping_transformer">
<span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">beta_warping_transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#beta_warping_transformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.beta_warping_transformer" title="Link to this definition">¶</a></dt>
<dd><p>Create a scikit-learn FunctionTransformer for Beta CDF warping.</p>
<section id="id12">
<h3>Parameters<a class="headerlink" href="#id12" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>alpha<span class="classifier">float or array-like</span></dt><dd><p>Shape parameter α for Beta distribution</p>
</dd>
<dt>beta<span class="classifier">float or array-like</span></dt><dd><p>Shape parameter β for Beta distribution</p>
</dd>
</dl>
</section>
<section id="id13">
<h3>Returns<a class="headerlink" href="#id13" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>transformer<span class="classifier">FunctionTransformer</span></dt><dd><p>Scikit-learn transformer object</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="alabi.utility.NewFunctionTransformer">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">alabi.utility.</span></span><span class="sig-name descname"><span class="pre">NewFunctionTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accept_sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names_out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inv_kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#NewFunctionTransformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.NewFunctionTransformer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionTransformer</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="alabi.utility.NewFunctionTransformer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accept_sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names_out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inv_kw_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/utility.html#NewFunctionTransformer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.utility.NewFunctionTransformer.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-alabi.visualization">
<span id="alabi-visualization-module"></span><h2>alabi.visualization module<a class="headerlink" href="#module-alabi.visualization" title="Link to this heading">¶</a></h2>
<section id="visualization-py">
<h3><code class="xref py py-mod docutils literal notranslate"><span class="pre">visualization.py</span></code><a class="headerlink" href="#visualization-py" title="Link to this heading">¶</a></h3>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_error_vs_iteration">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_error_vs_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iteration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_error</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_error</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Error'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GP</span> <span class="pre">fit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savedir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_error_vs_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_error_vs_iteration" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_hyperparam_vs_iteration">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_hyperparam_vs_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GP</span> <span class="pre">fit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_hyperparam_vs_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_hyperparam_vs_iteration" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_train_time_vs_iteration">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_train_time_vs_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GP</span> <span class="pre">fit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_train_time_vs_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_train_time_vs_iteration" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_corner_lnp">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_corner_lnp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_corner_lnp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_corner_lnp" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_corner_scatter">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_corner_scatter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_corner_scatter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_corner_scatter" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_gp_fit_1D">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_gp_fit_1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GP</span> <span class="pre">fit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_gp_fit_1D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_gp_fit_1D" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_gp_fit_2D">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_gp_fit_2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngrid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'GP</span> <span class="pre">fit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Blues_r'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_gp_fit_2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_gp_fit_2D" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_contour_2D">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_contour_2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngrid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Blues_r'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_contour_2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_contour_2D" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_true_fit_2D">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_true_fit_2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngrid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_true_fit_2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_true_fit_2D" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_utility_2D">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_utility_2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngrid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_utility_2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_utility_2D" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_dynesty_traceplot">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_dynesty_traceplot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_dynesty_traceplot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_dynesty_traceplot" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_dynesty_runplot">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_dynesty_runplot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_dynesty_runplot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_dynesty_runplot" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_mcmc_comparison">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_mcmc_comparison</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sampler</span> <span class="pre">1</span> <span class="pre">posterior'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sampler</span> <span class="pre">2</span> <span class="pre">posterior'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savedir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mcmc_comparison.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['orange',</span> <span class="pre">'royalblue']</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_mcmc_comparison"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_mcmc_comparison" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_sampler_comparison">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_sampler_comparison</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_sampler_comparison"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_sampler_comparison" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="alabi.visualization.plot_2D_panel4">
<span class="sig-prename descclassname"><span class="pre">alabi.visualization.</span></span><span class="sig-name descname"><span class="pre">plot_2D_panel4</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">savename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/alabi/visualization.html#plot_2D_panel4"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#alabi.visualization.plot_2D_panel4" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="modules.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">alabi</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021, Jess Birky
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">alabi package</a><ul>
<li><a class="reference internal" href="#module-alabi.benchmarks">alabi.benchmarks module</a><ul>
<li><a class="reference internal" href="#benchmarks-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">benchmarks.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.benchmarks.random_gaussian_covariance"><code class="docutils literal notranslate"><span class="pre">random_gaussian_covariance()</span></code></a></li>
<li><a class="reference internal" href="#alabi.benchmarks.multimodal_gaussian_nd"><code class="docutils literal notranslate"><span class="pre">multimodal_gaussian_nd()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.cache_utils">alabi.cache_utils module</a><ul>
<li><a class="reference internal" href="#cache-utils-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cache_utils.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.cache_utils.load_pickle"><code class="docutils literal notranslate"><span class="pre">load_pickle()</span></code></a></li>
<li><a class="reference internal" href="#alabi.cache_utils.load_model_cache"><code class="docutils literal notranslate"><span class="pre">load_model_cache()</span></code></a></li>
<li><a class="reference internal" href="#alabi.cache_utils.write_report_gp"><code class="docutils literal notranslate"><span class="pre">write_report_gp()</span></code></a></li>
<li><a class="reference internal" href="#alabi.cache_utils.write_report_emcee"><code class="docutils literal notranslate"><span class="pre">write_report_emcee()</span></code></a></li>
<li><a class="reference internal" href="#alabi.cache_utils.write_report_dynesty"><code class="docutils literal notranslate"><span class="pre">write_report_dynesty()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.core">alabi.core module</a><ul>
<li><a class="reference internal" href="#core-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">core.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel"><code class="docutils literal notranslate"><span class="pre">SurrogateModel</span></code></a><ul>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.gp"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.gp</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.bounds"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.bounds</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel._bounds"><code class="docutils literal notranslate"><span class="pre">SurrogateModel._bounds</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel._theta"><code class="docutils literal notranslate"><span class="pre">SurrogateModel._theta</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel._y"><code class="docutils literal notranslate"><span class="pre">SurrogateModel._y</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.ntrain"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.ntrain</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.ndim"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.ndim</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.emcee_samples"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.emcee_samples</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.dynesty_samples"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.dynesty_samples</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.__init__"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.__init__()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.save"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.save()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.theta"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.theta()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.y"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.y()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.refit_scalers"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.refit_scalers()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.init_train"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.init_train()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.load_train"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.load_train()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.init_samples"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.init_samples()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.set_hyperparam_prior_bounds"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.set_hyperparam_prior_bounds()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.expand_hyperparameter_vector"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.expand_hyperparameter_vector()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.set_hyperparameter_vector"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.set_hyperparameter_vector()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.get_hyperparameter_dict"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.get_hyperparameter_dict()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.get_hyperparameter_vector"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.get_hyperparameter_vector()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.init_gp"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.init_gp()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.eval_gp_at_iteration"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.eval_gp_at_iteration()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.surrogate_log_likelihood"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.surrogate_log_likelihood()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.surrogate_likelihood"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.surrogate_likelihood()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.create_cached_surrogate_likelihood"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.create_cached_surrogate_likelihood()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.find_next_point"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.find_next_point()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.active_train"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.active_train()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.active_train_parallel"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.active_train_parallel()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.lnprob"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.lnprob()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.find_map"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.find_map()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.run_emcee"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.run_emcee()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.run_dynesty"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.run_dynesty()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.run_pymultinest"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.run_pymultinest()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.run_ultranest"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.run_ultranest()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.plot"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.plot()</span></code></a></li>
<li><a class="reference internal" href="#alabi.core.SurrogateModel.get_chain_diversity_metrics"><code class="docutils literal notranslate"><span class="pre">SurrogateModel.get_chain_diversity_metrics()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#alabi.core.CachedSurrogateLikelihood"><code class="docutils literal notranslate"><span class="pre">CachedSurrogateLikelihood</span></code></a><ul>
<li><a class="reference internal" href="#alabi.core.CachedSurrogateLikelihood.__init__"><code class="docutils literal notranslate"><span class="pre">CachedSurrogateLikelihood.__init__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.gp_utils">alabi.gp_utils module</a><ul>
<li><a class="reference internal" href="#gp-utils-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">gp_utils.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.gp_utils.configure_gp"><code class="docutils literal notranslate"><span class="pre">configure_gp()</span></code></a></li>
<li><a class="reference internal" href="#alabi.gp_utils.optimize_gp"><code class="docutils literal notranslate"><span class="pre">optimize_gp()</span></code></a></li>
<li><a class="reference internal" href="#alabi.gp_utils.optimize_gp_kfold_cv"><code class="docutils literal notranslate"><span class="pre">optimize_gp_kfold_cv()</span></code></a></li>
<li><a class="reference internal" href="#alabi.gp_utils.regularization_term"><code class="docutils literal notranslate"><span class="pre">regularization_term()</span></code></a></li>
<li><a class="reference internal" href="#alabi.gp_utils.regularization_gradient"><code class="docutils literal notranslate"><span class="pre">regularization_gradient()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.mcmc_utils">alabi.mcmc_utils module</a><ul>
<li><a class="reference internal" href="#mcmc-utils-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mcmc_utils.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.mcmc_utils.estimate_burnin"><code class="docutils literal notranslate"><span class="pre">estimate_burnin()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.utility">alabi.utility module</a><ul>
<li><a class="reference internal" href="#utility-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">utility.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.agp_utility"><code class="docutils literal notranslate"><span class="pre">agp_utility()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.bape_utility"><code class="docutils literal notranslate"><span class="pre">bape_utility()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.jones_utility"><code class="docutils literal notranslate"><span class="pre">jones_utility()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.assign_utility"><code class="docutils literal notranslate"><span class="pre">assign_utility()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.minimize_objective"><code class="docutils literal notranslate"><span class="pre">minimize_objective()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.prior_sampler"><code class="docutils literal notranslate"><span class="pre">prior_sampler()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.prior_sampler_normal"><code class="docutils literal notranslate"><span class="pre">prior_sampler_normal()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.lnprior_uniform"><code class="docutils literal notranslate"><span class="pre">lnprior_uniform()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.prior_transform_uniform"><code class="docutils literal notranslate"><span class="pre">prior_transform_uniform()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.lnprior_normal"><code class="docutils literal notranslate"><span class="pre">lnprior_normal()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.prior_transform_normal"><code class="docutils literal notranslate"><span class="pre">prior_transform_normal()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction</span></code></a><ul>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction.__init__"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction.__init__()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction.fit"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction.fit()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction.transform"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction.transform()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction.fit_transform"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction.fit_transform()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.BetaWarpingFunction.inverse_transform"><code class="docutils literal notranslate"><span class="pre">BetaWarpingFunction.inverse_transform()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#alabi.utility.beta_warping_transformer"><code class="docutils literal notranslate"><span class="pre">beta_warping_transformer()</span></code></a></li>
<li><a class="reference internal" href="#alabi.utility.NewFunctionTransformer"><code class="docutils literal notranslate"><span class="pre">NewFunctionTransformer</span></code></a><ul>
<li><a class="reference internal" href="#alabi.utility.NewFunctionTransformer.__init__"><code class="docutils literal notranslate"><span class="pre">NewFunctionTransformer.__init__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-alabi.visualization">alabi.visualization module</a><ul>
<li><a class="reference internal" href="#visualization-py"><code class="xref py py-mod docutils literal notranslate"><span class="pre">visualization.py</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_error_vs_iteration"><code class="docutils literal notranslate"><span class="pre">plot_error_vs_iteration()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_hyperparam_vs_iteration"><code class="docutils literal notranslate"><span class="pre">plot_hyperparam_vs_iteration()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_train_time_vs_iteration"><code class="docutils literal notranslate"><span class="pre">plot_train_time_vs_iteration()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_corner_lnp"><code class="docutils literal notranslate"><span class="pre">plot_corner_lnp()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_corner_scatter"><code class="docutils literal notranslate"><span class="pre">plot_corner_scatter()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_gp_fit_1D"><code class="docutils literal notranslate"><span class="pre">plot_gp_fit_1D()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_gp_fit_2D"><code class="docutils literal notranslate"><span class="pre">plot_gp_fit_2D()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_contour_2D"><code class="docutils literal notranslate"><span class="pre">plot_contour_2D()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_true_fit_2D"><code class="docutils literal notranslate"><span class="pre">plot_true_fit_2D()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_utility_2D"><code class="docutils literal notranslate"><span class="pre">plot_utility_2D()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_dynesty_traceplot"><code class="docutils literal notranslate"><span class="pre">plot_dynesty_traceplot()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_dynesty_runplot"><code class="docutils literal notranslate"><span class="pre">plot_dynesty_runplot()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_mcmc_comparison"><code class="docutils literal notranslate"><span class="pre">plot_mcmc_comparison()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_sampler_comparison"><code class="docutils literal notranslate"><span class="pre">plot_sampler_comparison()</span></code></a></li>
<li><a class="reference internal" href="#alabi.visualization.plot_2D_panel4"><code class="docutils literal notranslate"><span class="pre">plot_2D_panel4()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=d45e8c67"></script>
    <script src="_static/doctools.js?v=fd6eb6e6"></script>
    <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    <script src="_static/notebook-outputs.js?v=9bb603c3"></script>
    </body>
</html>